% Encoding: UTF-8

@Article{Chen1998,
  author    = {Chen, Scott Shaobing and Donoho, David L. and Saunders, Michael A.},
  title     = {Atomic Decomposition by Basis Pursuit},
  journal   = {SIAM Journal on Scientific Computing},
  year      = {1998},
  volume    = {20},
  number    = {1},
  pages     = {33--61},
  issn      = {1064-8275},
  abstract  = {The time-frequency and time-scale communities have recently developed a large number of overcomplete waveform dictionaries --- stationary wavelets, wavelet packets, cosine packets, chirplets, and warplets, to name a few. Decomposition into overcomplete systems is not unique, and several methods for decomposition have been proposed, including the method of frames (MOF), Matching pursuit (MP), and, for special dictionaries, the best orthogonal basis (BOB). Basis Pursuit (BP) is a principle for decomposing a signal into an "optimal" superposition of dictionary elements, where optimal means having the smallest l1 norm of coefficients among all such decompositions. We give examples exhibiting several advantages over MOF, MP, and BOB, including better sparsity and superresolution. BP has interesting relations to ideas in areas as diverse as ill-posed problems, in abstract harmonic analysis, total variation denoising, and multiscale edge denoising. BP in highly overcomplete dictionaries leads to large-scale optimization problems. With signals of length 8192 and a wavelet packet dictionary, one gets an equivalent linear program of size 8192 by 212,992. Such problems can be attacked successfully only because of recent advances in linear programming by interior-point methods. We obtain reasonable success with a primal-dual logarithmic barrier method and conjugate-gradient solver.},
  file      = {:references/Atomic Decomposition by Basis Pursuit/unhighlighted.pdf:PDF},
  groups    = {FAEFS},
  keywords  = {94a12 ; 65k05 ; 65d15 ; 41a45 ; Overcomplete Signal Representation ; Interior-Point Methods For Linear Programming ; Total Variation Denoising ; Multiscale Edges ; Denoising ; Time-Frequency Analysis ; Time-Scale Analysis ; $\Ell^1$ Norm Optimization ; Matching Pursuit ; Wavelets ; Wavelet Packets ; Cosine Packets},
  language  = {eng},
  publisher = {Society for Industrial and Applied Mathematics},
}

@Misc{Zischke2018,
  author = {Zischke, Ryan},
  title  = {Requirements Analysis},
  month  = mar,
  year   = {2018},
  groups = {FAEFS},
}

@Misc{Zischke2018a,
  author = {Zischke, Ryan},
  title  = {Progress Report},
  month  = may,
  year   = {2018},
  groups = {FAEFS},
}

@Article{VanderPlas2018,
  author   = {Jacob T. VanderPlas},
  title    = {Understanding the Lomb–Scargle Periodogram},
  journal  = {The Astrophysical Journal Supplement Series},
  year     = {2018},
  volume   = {236},
  number   = {1},
  pages    = {16},
  abstract = {The Lomb–Scargle periodogram is a well-known algorithm for detecting and characterizing periodic signals in unevenly sampled data. This paper presents a conceptual introduction to the Lomb–Scargle periodogram and important practical considerations for its use. Rather than a rigorous mathematical treatment, the goal of this paper is to build intuition about what assumptions are implicit in the use of the Lomb–Scargle periodogram and related estimators of periodicity, so as to motivate important practical considerations required in its proper application and interpretation.},
  file     = {:references/Understanding the Lomb-Scargle Periodogram/highlighted.pdf:PDF},
  groups   = {FAEFS},
  url      = {http://stacks.iop.org/0067-0049/236/i=1/a=16},
}

@Online{Kerrisk2018,
  author = {Kerrisk, Michael},
  title  = {Linux Man Pages Online},
  year   = {2018},
  groups = {FAEFS},
  url    = {http://man7.org/linux/man-pages/},
}

@Online{Heesch2018,
  author = {Heesch, Dimitry van},
  title  = {Doxygen},
  month  = jan,
  year   = {2018},
  groups = {FAEFS},
  url    = {http://www.doxygen.org/},
}

@Online{Gouy2018,
  author = {Gouy, Isaac},
  title  = {The Computer Language Benchmarks Game},
  month  = may,
  year   = {2018},
  groups = {FAEFS},
  url    = {https://benchmarksgame-team.pages.debian.net/benchmarksgame/},
}

@Online{Boost2018,
  author       = {Boost},
  title        = {{Boost C++ Libraries}},
  howpublished = {https://www.boost.org},
  month        = apr,
  year         = {2018},
  groups       = {FAEFS},
  url          = {http://www.boost.org/},
}

@Article{Seghouani2017,
  author  = {Seghouani, N.},
  title   = {High-resolution spectral analysis of unevenly spaced data using a regularization approach},
  journal = {Monthly Notices of the Royal Astronomical Society},
  year    = {2017},
  volume  = {468},
  number  = {3},
  pages   = {3312-3321},
  doi     = {10.1093/mnras/stx569},
  eprint  = {/oup/backfile/content_public/journal/mnras/468/3/10.1093_mnras_stx569/1/stx569.pdf},
  file    = {:references/High-resolution spectral analysis of unevenly spaced data using a regularization approach/highlighted.pdf:PDF},
  groups  = {FAEFS},
  url     = {http://dx.doi.org/10.1093/mnras/stx569},
}

@Article{Langrene2017,
  author        = {{Langren{\'e}}, N. and {Warin}, X.},
  title         = {{Fast and stable multivariate kernel density estimation by fast sum updating}},
  journal       = {ArXiv e-prints},
  year          = {2017},
  month         = dec,
  adsnote       = {Provided by the SAO/NASA Astrophysics Data System},
  adsurl        = {http://adsabs.harvard.edu/abs/2017arXiv171200993L},
  archiveprefix = {arXiv},
  eprint        = {1712.00993},
  file          = {:/home/ryan/ownCloud/2018/Uni/ECE4094 and ECE4095 - Final Year Project/Research/references/Fast and Stable Multivariate Kernel Density Estimation by Fast Sum Updating/highlighted.pdf:PDF},
  groups        = {FAEFS},
  keywords      = {Statistics - Computation, 62G07, 62G08, 65C60, G.3, F.2.1, G.1.0},
  primaryclass  = {stat.CO},
}

@Book{Harrell2015a,
  title     = {Regression modeling strategies : with applications to linear models, logistic and ordinal regression, and survival analysis},
  publisher = {Springer, Cham},
  year      = {2015},
  author    = {Harrell, Frank E., Jr.},
  series    = {Springer series in statistics},
  edition   = {Second edition.},
  isbn      = {9783319194257},
  abstract  = {This highly anticipated second edition features new chapters and sections, 225 new references, and comprehensive R software. In keeping with the previous edition, this book is about the art and science of data analysis and predictive modeling, which entails choosing and using multiple tools. Instead of presenting isolated techniques, this text emphasizes problem solving strategies that address the many issues arising when developing multivariable models using real data and not standard textbook examples. It includes imputation methods for dealing with missing data effectively, methods for fitting nonlinear relationships and for making the estimation of transformations a formal part of the modeling process, methods for dealing with "too many variables to analyze and not enough observations," and powerful model validation techniques based on the bootstrap.℗ℓ The reader will gain a keen understanding of predictive accuracy, and the harm of categorizing continuous predictors or outcomes.℗ℓ This text realistically deals with model uncertainty, and its effects on inference, to achieve "safe data mining." It also presents many graphical methods for communicating complex regression models to non-statisticians. Regression Modeling Strategies presents full-scale case studies of non-trivial datasets instead of over-simplified illustrations of each method. These case studies use freely available R functions that make the multiple imputation, model building, validation, and interpretation tasks described in the book relatively easy to do. Most of the methods in this text apply to all regression models, but special emphasis is given to multiple regression using generalized least squares for longitudinal data, the binary logistic model, models for ordinal responses, parametric survival regression models, and the Cox semiparametric survival model.℗ℓ A new emphasis is given to the robust analysis of continuous dependent variables using ordinal regression. As in the first edition, this text is intended for Masters' or Ph. D. level graduate students who have had a general introductory probability and statistics course and who are well versed in ordinary multiple regression and intermediate algebra. The book will also serve as a reference for data analysts and statistical methodologists, as it contains an up-to-date survey and bibliography of modern statistical modeling techniques. Examples used in the text mostly come from biomedical research, but the methods are applicable anywhere predictive models ("analytics") are useful, including economics, epidemiology, sociology, psychology, engineering, and marketing.},
  file      = {:references/Regression Modeling Strategies/highlighted.pdf:PDF},
  groups    = {FAEFS},
  issn      = {9783319194240},
  keywords  = {Regression analysis},
  language  = {eng},
}

@Article{Zychaluk2014,
  author    = {K. \.Zychaluk},
  journal   = {Journal of Nonparametric Statistics},
  title     = {Bootstrap bandwidth selection method for local linear estimator in exponential family models},
  year      = {2014},
  number    = {2},
  pages     = {305-319},
  volume    = {26},
  abstract  = {Many biological experiments involve data whose distribution belongs to the exponential family. Such data are often analysed using generalised linear models but this method requires specification of the link function which can have strong influence on the resulting estimate. Instead a local method based on quasi-likelihood can be used, but the choice of the smoothing parameter is crucial for its performance. A bootstrap bandwidth selection method is proposed and shown to be consistent. Examples of application to data from biological and psychometric experiments are given.},
  doi       = {10.1080/10485252.2014.885023},
  eprint    = {https://doi.org/10.1080/10485252.2014.885023},
  file      = {:references/Bootstrap Bandwidth Selection Method for Local Linear Estimator in Exponential Family Models/highlighted.pdf:PDF},
  groups    = {FAEFS},
  publisher = {Taylor \& Francis},
  url       = {https://doi.org/10.1080/10485252.2014.885023},
}

@Article{Leroy2012,
  author  = {{Leroy, B.}},
  title   = {Fast calculation of the Lomb-Scargle periodogram using nonequispaced fast Fourier transforms},
  journal = {A\&A},
  year    = {2012},
  volume  = {545},
  pages   = {A50},
  doi     = {10.1051/0004-6361/201219076},
  file    = {:references/Fast Calculation of the Lomb-Scargle Periodogram using Nonequispaced Fast Fourier Transforms/Unhighlighted.pdf:PDF},
  groups  = {FAEFS},
  url     = {https://doi.org/10.1051/0004-6361/201219076},
}

@Article{Kunis2012,
  author    = {Kunis, Susanne and Kunis, Stefan},
  title     = {The nonequispaced FFT on graphics processing units},
  journal   = {PAMM},
  year      = {2012},
  volume    = {12},
  number    = {1},
  pages     = {7--10},
  month     = {12},
  issn      = {1617-7061},
  abstract  = {Without doubt, the fast Fourier transform (FFT) belongs to the algorithms with large impact on science and engineering. By appropriate approximations, this scheme has been generalized for arbitrary spatial sampling points. This so called nonequispaced FFT is the core of the sequential NFFT3 library and we discuss its computational costs in detail. On the other hand, programmable graphics processing units have evolved into highly parallel, multithreaded, manycore processors with enormous computational capacity and very high memory bandwidth. By means of the so called Compute Unified Device Architecture (CUDA), we parallelized the nonequispaced FFT using the CUDA FFT library and a dedicated parallelization of the approximation scheme. (© 2012 Wiley-VCH Verlag GmbH & Co. KGaA, Weinheim)},
  comment   = {API is very similar to the NFFT3 library for the CPU.
See here for code:
https://github.com/sukunis/CUNFFT},
  doi       = {10.1002/pamm.201210003},
  file      = {:references/The nonequispaced FFT on graphics processing units/unhighlighted.pdf:PDF},
  groups    = {FAEFS},
  publisher = {Wiley Online Library},
  url       = {http:https://doi.org/10.1002/pamm.201210003},
}

@Article{Raykar2010,
  author    = {Vikas C. Raykar and Ramani Duraiswami and Linda H. Zhao},
  journal   = {Journal of Computational and Graphical Statistics},
  title     = {Fast Computation of Kernel Estimators},
  year      = {2010},
  number    = {1},
  pages     = {205-220},
  volume    = {19},
  abstract  = {The computational complexity of evaluating the kernel density estimate (or its derivatives) at m evaluation points given n sample points scales quadratically as O(nm)—making it prohibitively expensive for large datasets. While approximate methods like binning could speed up the computation, they lack a precise control over the accuracy of the approximation. There is no straightforward way of choosing the binning parameters a priori in order to achieve a desired approximation error. We propose a novel computationally efficient ε-exact approximation algorithm for the univariate Gaussian kernel-based density derivative estimation that reduces the computational complexity from O(nm) to linear O(n+m). The user can specify a desired accuracy ε. The algorithm guarantees that the actual error between the approximation and the original kernel estimate will always be less than ε. We also apply our proposed fast algorithm to speed up automatic bandwidth selection procedures. We compare our method to the best available binning methods in terms of the speed and the accuracy. Our experimental results show that the proposed method is almost twice as fast as the best binning methods and is around five orders of magnitude more accurate. The software for the proposed method is available online.},
  doi       = {10.1198/jcgs.2010.09046},
  eprint    = {https://doi.org/10.1198/jcgs.2010.09046},
  file      = {:/home/ryan/ownCloud/2018/Uni/ECE4094 and ECE4095 - Final Year Project/Research/references/Fast Computation of Kernel Estimators/highlighted.pdf:PDF},
  groups    = {FAEFS},
  publisher = {Taylor \& Francis},
  url       = {https://doi.org/10.1198/jcgs.2010.09046},
}

@Online{Guennebaud2010,
  author = {Ga\"{e}l Guennebaud and Beno\^{i}t Jacob and others},
  title  = {Eigen v3},
  year   = {2010},
  groups = {FAEFS},
  url    = {https://eigen.tuxfamily.org/},
}

@Article{ZechmeisterM.2009,
  author  = {{Zechmeister, M.} and {K\"urster, M.}},
  title   = {The generalised Lomb-Scargle periodogram - A new formalism for the floating-mean and Keplerian periodograms},
  journal = {A\&A},
  year    = {2009},
  volume  = {496},
  number  = {2},
  pages   = {577-584},
  doi     = {10.1051/0004-6361:200811296},
  file    = {:references/The generalised Lomb-Scargle periodogram/highlighted.pdf:PDF},
  groups  = {FAEFS},
  url     = {https://doi.org/10.1051/0004-6361:200811296},
}

@Article{Robinson2009,
  author    = {Robinson, Peter M},
  title     = {ON DISCRETE SAMPLING OF TIME-VARYING CONTINUOUS-TIME SYSTEMS},
  journal   = {Econometric Theory},
  year      = {2009},
  volume    = {25},
  number    = {4},
  pages     = {985--994},
  month     = {August},
  issn      = {0266-4666},
  abstract  = {We consider a multivariate continuous-time process, generated by a system of linear stochastic differential equations, driven by white noise, and involving coefficients that possibly vary over time. The process is observable only at discrete, but not necessarily equally-spaced, time points (though equal spacing significantly simplifies matters). Such settings represent partial extensions of ones studied extensively by A.R. Bergstrom. A model for the observed time series is deduced. Initially we focus on a first-order model, but higher-order models are discussed in the case of equally-spaced observations. Some discussion of issues of statistical inference is included.},
  comment   = {{ Two primary results: 1. A closed form solution for the first and second moments of discrete (but not generally equispaced) samples of Y(t) in dY(t) = A(t)Y(t)dt + B(t)dX(t) for column vector brownian motion X(t), and time varying non-random matrices A(t) and B(t). 2. Discrete and equispaced samples of the system in 1. and its higher order counterparts are special cases of ARMA models. }},
  doi       = {10.1017/s0266466608090373},
  file      = {:references/On Discrete Sampling of Time-Varying Continuous-Time Systems/On Discrete Sampling of Time-Varying Continuous-Time Systems.pdf:PDF;:references/On Discrete Sampling of Time-Varying Continuous-Time Systems/00FirstOrderSystem.png:PNG image;:references/On Discrete Sampling of Time-Varying Continuous-Time Systems/01PhiDefinition.png:PNG image;:references/On Discrete Sampling of Time-Varying Continuous-Time Systems/02SecondMomentOfFirstOrderSystem.png:PNG image;:references/On Discrete Sampling of Time-Varying Continuous-Time Systems/03HigherOrderSystem.png:PNG image;:references/On Discrete Sampling of Time-Varying Continuous-Time Systems/04HigherOrderSystemDiscrete.png:PNG image},
  groups    = {FAEFS},
  keywords  = {Econometrics ; Sampling ; Data Collection ; Time Series ; Estimation ; Economics;},
  publisher = {Cambridge University Press},
  timestamp = {2018-04-16},
}

@Article{Palmer2009,
  author   = {David M. Palmer},
  title    = {A Fast Chi-Squared Technique for Period Search of Irregularly Sampled Data},
  journal  = {The Astrophysical Journal},
  year     = {2009},
  volume   = {695},
  number   = {1},
  pages    = {496},
  abstract = {A new, computationally and statistically efficient algorithm, the Fast χ 2 algorithm (Fχ 2 ), can find a periodic signal with harmonic content in irregularly sampled data with nonuniform errors. The algorithm calculates the minimized χ 2 as a function of frequency at the desired number of harmonics, using fast Fourier transforms to provide O ( N log N ) performance. The code for a reference implementation is provided.},
  comment  = {The quoted computational complexity does not take into account the O(H^3) Gramian matrix matrix inversion.},
  file     = {:references/A Fast Chi-Squared Technique for Period Search of Irregularly Sampled Data/highlighted.pdf:PDF},
  groups   = {FAEFS},
  url      = {http://stacks.iop.org/0004-637X/695/i=1/a=496},
}

@InCollection{Morariu2009,
  author    = {Vlad I. Morariu and Balaji V. Srinivasan and Raykar, Vikas C and Ramani Duraiswami and Davis, Larry S},
  title     = {Automatic online tuning for fast Gaussian summation},
  booktitle = {Advances in Neural Information Processing Systems 21},
  publisher = {Curran Associates, Inc.},
  year      = {2009},
  editor    = {D. Koller and D. Schuurmans and Y. Bengio and L. Bottou},
  pages     = {1113--1120},
  abstract  = {Many machine learning algorithms require the summation of Gaussian kernel functions, an expensive operation if implemented straightforwardly. Several methods have been proposed to reduce the computational complexity of evaluating such sums, including tree and analysis based methods. These achieve varying speedups depending on the bandwidth, dimension, and prescribed error, making the choice between methods difficult for machine learning tasks. We provide an algorithm that combines tree methods with the Improved Fast Gauss Transform (IFGT). As originally proposed the IFGT suffers from two problems: (1) the Taylor series expansion does not perform well for very low bandwidths, and (2) parameter selection is not trivial and can drastically affect performance and ease of use. We address the first problem by employing a tree data structure, resulting in four evaluation methods whose performance varies based on the distribution of sources and targets and input parameters such as desired accuracy and bandwidth. To solve the second problem, we present an online tuning approach that results in a black box method that automatically chooses the evaluation method and its parameters to yield the best performance for the input data, desired accuracy, and bandwidth. In addition, the new IFGT parameter selection approach allows for tighter error bounds. Our approach chooses the fastest method at negligible additional cost, and has superior performance in comparisons with previous approaches.},
  file      = {:/home/ryan/ownCloud/2018/Uni/ECE4094 and ECE4095 - Final Year Project/Research/references/Automatic Online Tuning for Fast Gaussian Summation/highlighted.pdf:PDF},
  groups    = {FAEFS},
  url       = {http://papers.nips.cc/paper/3420-automatic-online-tuning-for-fast-gaussian-summation.pdf},
}

@Article{Keiner2009,
  author     = {Keiner, Jens and Kunis, Stefan and Potts, Daniel},
  title      = {Using NFFT 3---A Software Library for Various Nonequispaced Fast Fourier Transforms},
  journal    = {ACM Trans. Math. Softw.},
  year       = {2009},
  volume     = {36},
  number     = {4},
  pages      = {19:1--19:30},
  month      = aug,
  issn       = {0098-3500},
  acmid      = {1555388},
  address    = {New York, NY, USA},
  articleno  = {19},
  comment    = {See section three for tutorial on using the software api.
The transform direction is reversed  for the NFFT: the raw NFFT goes from the frequency domain to the time domain, and the adjoint NFFT goes from the time domain to the frequency domain.
See here for code and documentation:
https://www-user.tu-chemnitz.de/~potts/nfft/index.php},
  doi        = {10.1145/1555386.1555388},
  file       = {:references/Using NFFT 3 - A Software Library for Various Nonequispaced Fast Fourier Transforms/unhighlighted.pdf:PDF},
  groups     = {FAEFS},
  issue_date = {August 2009},
  keywords   = {Fast Fourier transforms, approximative algorithms},
  numpages   = {30},
  publisher  = {ACM},
  url        = {http://doi.acm.org.ezproxy.lib.monash.edu.au/10.1145/1555386.1555388},
}

@InProceedings{Yang2003,
  author    = {C. Yang and R. Duraiswami and N. A. Gumerov and L. Davis},
  title     = {Improved fast gauss transform and efficient kernel density estimation},
  booktitle = {Proceedings Ninth IEEE International Conference on Computer Vision},
  year      = {2003},
  pages     = {664-671 vol.1},
  month     = {Oct},
  abstract  = {Evaluating sums of multivariate Gaussians is a common computational task in computer vision and pattern recognition, including in the general and powerful kernel density estimation technique. The quadratic computational complexity of the summation is a significant barrier to the scalability of this algorithm to practical applications. The fast Gauss transform (FGT) has successfully accelerated the kernel density estimation to linear running time for low-dimensional problems. Unfortunately, the cost of a direct extension of the FGT to higher-dimensional problems grows exponentially with dimension, making it impractical for dimensions above 3. We develop an improved fast Gauss transform to efficiently estimate sums of Gaussians in higher dimensions, where a new multivariate expansion scheme and an adaptive space subdivision technique dramatically improve the performance. The improved FGT has been applied to the mean shift algorithm achieving linear computational complexity. Experimental results demonstrate the efficiency and effectiveness of our algorithm.},
  doi       = {10.1109/ICCV.2003.1238383},
  file      = {:/home/ryan/ownCloud/2018/Uni/ECE4094 and ECE4095 - Final Year Project/Research/references/Improved Fast Gauss Transform and Efficient Kernel Density Estimation/highlighted.pdf:PDF},
  groups    = {FAEFS},
  keywords  = {Gaussian processes;computational complexity;computer vision;estimation theory;adaptive space subdivision technique;computer vision;fast Gauss transform;kernel density estimation;mean shift algorithm;multivariate expansion scheme;pattern recognition;quadratic computational complexity;Application software;Bandwidth;Computational complexity;Computer vision;Density functional theory;Gaussian processes;Kernel;Nails;Parametric statistics;Pattern recognition},
}

@Article{Hall2000,
  author  = {Hall, P and Reimann, J and Rice, J},
  title   = {Nonparametric estimation of a periodic function},
  journal = {Biometrika},
  year    = {2000},
  volume  = {87},
  number  = {3},
  pages   = {545-557},
  doi     = {10.1093/biomet/87.3.545},
  eprint  = {/oup/backfile/content_public/journal/biomet/87/3/10.1093/biomet/87.3.545/2/870545.pdf},
  file    = {:references/Nonparametric estimation of a periodic function/highlighted.pdf:PDF},
  groups  = {FAEFS},
  url     = {http://dx.doi.org/10.1093/biomet/87.3.545},
}

@Article{EyerL.1999,
  author  = {{Eyer, L.} and {Bartholdi, P.}},
  title   = {Variable stars: Which Nyquist frequency?},
  journal = {Astron. Astrophys. Suppl. Ser.},
  year    = {1999},
  volume  = {135},
  number  = {1},
  pages   = {1-3},
  doi     = {10.1051/aas:1999102},
  file    = {:references/Variable stars\: Which Nyquist frequency?/highlighted.pdf:PDF},
  groups  = {FAEFS},
  url     = {https://doi.org/10.1051/aas:1999102},
}

@Article{Cumming1999,
  author   = {Andrew Cumming and Geoffrey W. Marcy and R. Paul Butler},
  title    = {The Lick Planet Search: Detectability and Mass Thresholds},
  journal  = {The Astrophysical Journal},
  year     = {1999},
  volume   = {526},
  number   = {2},
  pages    = {890},
  abstract = {We present an analysis of 11 yr of precision radial velocity measurements of 76 nearby solar-type stars from the Lick radial velocity survey. For each star, we report on variability, periodicity, and long-term velocity trends. Our sample of stars contains eight known companions with mass ( M p sin i ) less than 8 Jupiter masses ( M J ), six of which were discovered at Lick. For the remaining stars, we place upper limits on the companion mass as a function of orbital period. For most stars, we can exclude companions with velocity amplitude K ##IMG## [http://ej.iop.org/icons/Entities/gtrsim.gif] {gtrsim} 20 m s -1 at the 99% level, or M p sin i ##IMG## [http://ej.iop.org/icons/Entities/gtrsim.gif] {gtrsim} 0.7 M J ( a /AU) 1/2 for orbital radii a ##IMG## [http://ej.iop.org/icons/Entities/lesssim.gif] {lesssim} 5 AU. We examine the implications of our results for the observed distribution of mass and orbital radius of companions. We show that the combination of intrinsic stellar variability and measurement errors most likely explains why all confirmed companions so far have K ##IMG## [http://ej.iop.org/icons/Entities/gtrsim.gif] {gtrsim} 40 m s -1 . The finite duration of the observations limits detection of Jupiter-mass companions to a ##IMG## [http://ej.iop.org/icons/Entities/lesssim.gif] {lesssim} 3 AU. Thus it remains possible that the majority of solar-type stars harbor Jupiter-mass companions much like our own, and if so these companions should be detectable in a few years. It is striking that more massive companions with M p sin i > 3 M J are rare at orbital radii 4-6 AU; we could have detected such objects in ~90% of stars, yet found none. The observed companions show a "piling-up" toward small orbital radii, and there is a paucity of confirmed and candidate companions with orbital radii between ~0.2 and ~1 AU. The small number of confirmed companions means that we are not able to rule out selection effects as the cause of these features. We show that the traditional method for detecting periodicities, the Lomb-Scargle periodogram, fails to account for statistical fluctuations in the mean of a sampled sinusoid, making it nonrobust when the number of observations is small, the sampling is uneven, or for periods comparable to or greater than the duration of the observations. We adopt a "floating-mean" periodogram, in which the zero point of the sinusoid is allowed to vary during the fit. We discuss in detail the normalization of the periodogram and the probability distribution of periodogram powers. We stress that the three different prescriptions in the literature for normalizing the periodogram are statistically equivalent and that it is not possible to write a simple analytic form for the false alarm probability, making Monte Carlo methods essential.},
  file     = {:references/The Lick Planet Search\: Detectability and Mass Thresholds/unhighlighted.pdf:PDF},
  groups   = {FAEFS},
  url      = {http://stacks.iop.org/0004-637X/526/i=2/a=890},
}

@Article{Fan1996,
  author    = {Jianqing Fan and Irène Gijbels and Tien-Chung Hu and Li-Shan Huang},
  title     = {A STUDY OF VARIABLE BANDWIDTH SELECTION FOR LOCAL POLYNOMIAL REGRESSION},
  journal   = {Statistica Sinica},
  year      = {1996},
  volume    = {6},
  number    = {1},
  pages     = {113--127},
  issn      = {10170405, 19968507},
  abstract  = {A decisive question in nonparametric smoothing techniques is the choice of the bandwidth or smoothing parameter. The present paper addresses this question when using local polynomial approximations for estimating the regression function and its derivatives. A fully-automatic bandwidth selection procedure has been proposed by Fan and Gijbels (1995a), and the empirical performance of it was tested in detail via a variety of examples. Those experiences supported the methodology towards a great extend. In this paper we establish asymptotic results for the proposed variable bandwidth selector. We provide the rate of convergence of the bandwidth estimate, and obtain the asymptotic distribution of its error relative to the theoretical optimal variable bandwidth. These asymptotic properties give extra support to the proposed bandwidth selection procedure. It is also demonstrated how the proposed selection method can be applied in the density estimation setup. some examples illustrate this application.},
  file      = {:references/A Study of Variable Bandwidth Selection for Local Polynomial Regression/highlighted.pdf:PDF},
  groups    = {FAEFS},
  publisher = {Institute of Statistical Science, Academia Sinica},
  url       = {http://www.jstor.org/stable/24306002},
}

@Book{Fan1996a,
  title     = {Local polynomial modelling and its applications},
  publisher = {Chapman \& Hall},
  year      = {1996},
  author    = {Fan, Jianqing},
  series    = {Monographs on statistics and applied probability ; 66},
  address   = {London},
  isbn      = {0412983214},
  file      = {:/home/ryan/ownCloud/2018/Uni/ECE4094 and ECE4095 - Final Year Project/Research/references/Local Polynomial Modelling and Its Applications/Orthogonal Series Based Methods.pdf:PDF;:/home/ryan/ownCloud/2018/Uni/ECE4094 and ECE4095 - Final Year Project/Research/references/Local Polynomial Modelling and Its Applications/Bias and Variance.pdf:PDF;:/home/ryan/ownCloud/2018/Uni/ECE4094 and ECE4095 - Final Year Project/Research/references/Local Polynomial Modelling and Its Applications/Ideal Choice of Bandwidth.pdf:PDF;:/home/ryan/ownCloud/2018/Uni/ECE4094 and ECE4095 - Final Year Project/Research/references/Local Polynomial Modelling and Its Applications/Spectral Density Estimation.pdf:PDF;:/home/ryan/ownCloud/2018/Uni/ECE4094 and ECE4095 - Final Year Project/Research/references/Local Polynomial Modelling and Its Applications/Bibliography.pdf:PDF},
  groups    = {FAEFS},
  keywords  = {Regression analysis; Nonparametric statistics; Spline theory; Kernel functions; Smoothing (Statistics)},
  language  = {eng},
}

@Article{Fan1995a,
  author    = {Jianqing Fan and Nancy E. Heckman and M. P. Wand},
  journal   = {Journal of the American Statistical Association},
  title     = {Local Polynomial Kernel Regression for Generalized Linear Models and Quasi-Likelihood Functions},
  year      = {1995},
  number    = {429},
  pages     = {141-150},
  volume    = {90},
  abstract  = {Abstract We investigate the extension of the nonparametric regression technique of local polynomial fitting with a kernel weight to generalized linear models and quasi-likelihood contexts. In the ordinary regression case, local polynomial fitting has been seen to have several appealing features in terms of intuitive and mathematical simplicity. One noteworthy feature is the better performance near the boundaries compared to the traditional kernel regression estimators. These properties are shown to carry over to generalized linear model and quasi-likelihood settings. We also derive the asymptotic distributions of the proposed class of estimators that allow for straightforward interpretation and extensions of state-of-the-art bandwidth selection methods.},
  doi       = {10.1080/01621459.1995.10476496},
  eprint    = {https://www.tandfonline.com/doi/pdf/10.1080/01621459.1995.10476496},
  file      = {:/home/ryan/ownCloud/2018/Uni/ECE4094 and ECE4095 - Final Year Project/Research/references/Local Polynomial Kernel Regression for Generalized Linear Models and Quasi-Likelihood Functions/highlighted.pdf:PDF},
  groups    = {FAEFS},
  publisher = {Taylor \& Francis},
  url       = {https://www.tandfonline.com/doi/abs/10.1080/01621459.1995.10476496},
}

@Article{Fan1995,
  author    = {Jianqing Fan and Irene Gijbels},
  title     = {Data-Driven Bandwidth Selection in Local Polynomial Fitting: Variable Bandwidth and Spatial Adaptation},
  journal   = {Journal of the Royal Statistical Society. Series B (Methodological)},
  year      = {1995},
  volume    = {57},
  number    = {2},
  pages     = {371--394},
  issn      = {00359246},
  abstract  = {When estimating a mean regression function and its derivatives, locally weighted least squares regression has proven to be a very attractive technique. The present paper focuses on the important issue of how to select the smoothing parameter or bandwidth. In the case of estimating curves with a complicated structure, a variable bandwidth is desirable. Furthermore, the bandwidth should be indicated by the data themselves. Recent developments in nonparametric smoothing techniques inspired us to propose such a data-driven bandwidth selection procedure, which can be used to select both constant and variable bandwidths. The idea is based on a residual squares criterion along with a good approximation of the bias and variance of the estimator. The procedure can be applied to select bandwidths not only for estimating the regression curve but also for estimating its derivatives. The resulting estimation procedure has the necessary flexibility for capturing complicated shapes of curves. This is illustrated via a large variety of testing examples, including examples with a large spatial variability. The results are also compared with wavelet thresholding techniques, and it seems that our results are at least comparable, i.e. local polynomial regression using our data-driven variable bandwidth has spatial adaptation properties that are similar to wavelets.},
  file      = {:references/Data-Driven Bandwidth Selection in Local Polynomial Fitting\: Variable Bandwidth and Spatial Adaptation/highlighted.pdf:PDF},
  groups    = {FAEFS},
  publisher = {[Royal Statistical Society, Wiley]},
  url       = {http://www.jstor.org/stable/2345968},
}

@Article{Donoho1994,
  author    = {David L. Donoho},
  title     = {Statistical Estimation and Optimal Recovery},
  journal   = {The Annals of Statistics},
  year      = {1994},
  volume    = {22},
  number    = {1},
  pages     = {238--270},
  issn      = {00905364},
  abstract  = {New formulas are given for the minimax linear risk in estimating a linear functional of an unknown object from indirect data contaminated with random Gaussian noise. The formulas cover a variety of loss functions and do not require the symmetry of the convex a priori class. It is shown that affine minimax rules are within a few percent of minimax even among nonlinear rules, for a variety of loss functions. It is also shown that difficulty of estimation is measured by the modulus of continuity of the functional to be estimated. The method of proof exposes a correspondence between minimax affine estimates in the statistical estimation problem and optimal algorithms in the theory of optimal recovery.},
  file      = {:/home/ryan/ownCloud/2018/Uni/ECE4094 and ECE4095 - Final Year Project/Research/references/Statistical Estimation and Optimal Recovery/highlighted.pdf:PDF},
  groups    = {FAEFS},
  publisher = {Institute of Mathematical Statistics},
  url       = {http://www.jstor.org/stable/2242452},
}

@Article{Fan1993,
  author    = {Fan, Jianqing},
  title     = {Local Linear Regression Smoothers and Their Minimax Efficiencies},
  journal   = {Ann. Statist.},
  year      = {1993},
  volume    = {21},
  number    = {1},
  pages     = {196--216},
  month     = {03},
  abstract  = {In this paper we introduce a smooth version of local linear regression estimators and address their advantages. The MSE and MISE of the estimators are computed explicitly. It turns out that the local linear regression smoothers have nice sampling properties and high minimax efficiency-they are not only efficient in rates but also nearly efficient in constant factors. In the nonparametric regression context, the asymptotic minimax lower bound is developed via the heuristic of the "hardest onedimensional subproblem" of Donoho and Liu. Connections of the minimax risk with the modulus of continuity are made. The lower bound is also applicable for estimating conditional mean (regression) and conditional quantiles for both fixed and random design regression problems.},
  doi       = {10.1214/aos/1176349022},
  file      = {:references/Local Linear Regression Smoothers and their Minimax Efficiencies/Local Linear Regression Smoothers and their Minimax Efficiencies.pdf:PDF},
  fjournal  = {The Annals of Statistics},
  groups    = {FAEFS},
  publisher = {The Institute of Mathematical Statistics},
  url       = {https://doi.org/10.1214/aos/1176349022},
}

@Article{Hall1992,
  author    = {Peter Hall and Iain Johnstone},
  title     = {Empirical Functionals and Efficient Smoothing Parameter Selection},
  journal   = {Journal of the Royal Statistical Society. Series B (Methodological)},
  year      = {1992},
  volume    = {54},
  number    = {2},
  pages     = {475--530},
  issn      = {00359246},
  abstract  = {A striking feature of curve estimation is that the smoothing parameter <tex-math>$\hat h_0$</tex-math>, which minimizes the squared error of a kernel or smoothing spline estimator, is very difficult to estimate. This is manifest both in slow rates of convergence and in high variability of standard methods such as cross-validation. We quantify this difficulty by describing nonparametric information bounds and exhibit asymptotically efficient estimators of <tex-math>$\hat h_0$</tex-math> that attain the bounds. The efficient estimators are substantially less variable than cross-validation (and other current procedures) and simulations suggest that they may offer improvements at moderate sample sizes, at least in terms of minimizing the squared error. The key is a stochastic decomposition of the empirical functional <tex-math>$\hat h_0$</tex-math> in terms of a smooth quadratic functional of the unknown curve. Examples include the estimation of densities, regression functions and continuous signals in Gaussian white noise.},
  file      = {:references/Empirical Functionals and Efficient Smoothing Parameter Selection/highlighted.pdf:PDF},
  groups    = {FAEFS},
  publisher = {[Royal Statistical Society, Wiley]},
  url       = {http://www.jstor.org/stable/2346138},
}

@Article{Fan1992,
  author    = {Jianqing Fan},
  journal   = {Journal of the American Statistical Association},
  title     = {Design-adaptive Nonparametric Regression},
  year      = {1992},
  number    = {420},
  pages     = {998-1004},
  volume    = {87},
  abstract  = {Abstract In this article we study the method of nonparametric regression based on a weighted local linear regression. This method has advantages over other popular kernel methods. Moreover, such a regression procedure has the ability of design adaptation: It adapts to both random and fixed designs, to both highly clustered and nearly uniform designs, and even to both interior and boundary points. It is shown that the local linear regression smoothers have high asymptotic efficiency (i.e., can be 100\% with a suitable choice of kernel and bandwidth) among all possible linear smoothers, including those produced by kernel, orthogonal series, and spline methods. The finite sample property of the local linear regression smoother is illustrated via simulation studies. Nonparametric regression is frequently used to explore the association between covariates and responses. There are many versions of kernel regression smoothers. Some estimators are not good for random designs, such as in observational studies, and others are not good for nonequispaced designs. Furthermore, most nonparametric regression smoothers have “boundary effects” and require modifications at boundary points. However, the local linear regression smoothers do not share these disadvantages. They adapt to almost all regression settings and do not require any modifications even at boundary. Besides, this method has higher efficiency than other traditional nonparametric regression methods.},
  doi       = {10.1080/01621459.1992.10476255},
  eprint    = {https://www.tandfonline.com/doi/pdf/10.1080/01621459.1992.10476255},
  file      = {:references/Design Adaptive Nonparametric Regression/Design Adaptive Nonparametric Regression.pdf:PDF},
  groups    = {FAEFS},
  publisher = {Taylor \& Francis},
  url       = {https://www.tandfonline.com/doi/abs/10.1080/01621459.1992.10476255},
}

@Book{Kaplan1991,
  title     = {Advanced Calculus},
  publisher = {Addison-Wesley},
  year      = {1991},
  author    = {Kaplan, W.},
  series    = {Advanced book program},
  isbn      = {9780201578881},
  groups    = {FAEFS},
  lccn      = {lc91025336},
  url       = {https://books.google.com.au/books?id=p8vEQgAACAAJ},
}

@Article{Greengard1991,
  author   = {Greengard, L. and Strain, J.},
  journal  = {SIAM Journal on Scientific and Statistical Computing},
  title    = {The Fast Gauss Transform},
  year     = {1991},
  number   = {1},
  pages    = {79-94},
  volume   = {12},
  abstract = {Many problems in applied mathematics require the evaluation of the sum of N Gaussians at M points in space. The work required for direct evaluation grows like $NM$ as N and M increase; this makes it very expensive to carry out such calculations on a large scale. In this paper, an algorithm is presented which evaluates the sum of N Gaussians at M arbitrarily distributed points in $C \cdot (N + M)$ work, where C depends only on the precision required. When $N = M = 100,000$, the algorithm presented here is several thousand times faster than direct evaluation. It is based on a divide-and-conquer strategy, combined with the manipulation of Hermite expansions and Taylor series.},
  doi      = {10.1137/0912004},
  eprint   = {https://doi.org/10.1137/0912004},
  groups   = {FAEFS},
  url      = {https://doi.org/10.1137/0912004},
}

@Article{Press1989,
  author   = {{Press}, W.~H. and {Rybicki}, G.~B.},
  title    = {{Fast algorithm for spectral analysis of unevenly sampled data}},
  journal  = {Astrophysical Journal},
  year     = {1989},
  volume   = {338},
  pages    = {277-280},
  month    = mar,
  adsnote  = {Provided by the SAO/NASA Astrophysics Data System},
  adsurl   = {http://adsabs.harvard.edu/abs/1989ApJ...338..277P},
  doi      = {10.1086/167197},
  file     = {:references/Fast Algorithm for Spectral Analysis of Unevenly Sampled Data/Unhighlighted.pdf:PDF},
  groups   = {FAEFS},
  keywords = {Algorithms, Data Sampling, Fast Fourier Transformations, Spectrum Analysis, Computer Programs, Fortran},
}

@Article{Korenberg1989,
  author   = {Korenberg, M. J.},
  title    = {A robust orthogonal algorithm for system identification and time-series analysis},
  journal  = {Biological Cybernetics},
  year     = {1989},
  volume   = {60},
  number   = {4},
  pages    = {267--276},
  month    = {Feb},
  issn     = {1432-0770},
  abstract = {We describe and illustrate methods for obtaining a parsimonious sinusoidal series representation or model of biological time-series data. The methods are also used to identify nonlinear systems with unknown structure. A key aspect is a rapid search for significant terms to include in the model for the system or the time-series. For example, the methods use fast and robust orthogonal searches for significant frequencies in the time-series, and differ from conventional Fourier series analysis in several important respects. In particular, the frequencies in our resulting sinusoidal series need not be commensurate, nor integral multiples of the fundamental frequency corresponding to the record length. Freed of these restrictions, the methods produce a more economical sinusoidal series representation (than a Fourier series), finding the most significant frequencies first, and automatically determine model order. The methods are also capable of higher resolution than a conventional Fourier series analysis. In addition, the methods can cope with unequally-spaced or missing data, and are applicable to time-series corrupted by noise. Fially, we compare one of our methods with a wellknown technique for resolving sinusoidal signals in noise using published data for the test time-series.},
  day      = {01},
  doi      = {10.1007/BF00204124},
  file     = {:references/A Robust Orthogonal Algorithm for System Identification and Time-Series Analysis/highlighted.pdf:PDF},
  groups   = {FAEFS},
  url      = {https://doi.org/10.1007/BF00204124},
}

@Book{Bretthorst1988,
  title     = {Bayesian Spectrum Analysis and Parameter Estimation},
  publisher = {Springer New York},
  year      = {1988},
  author    = {Bretthorst, G. Larry},
  series    = {Lecture notes in statistics (Springer-Verlag) ; 48},
  address   = {New York, NY},
  isbn      = {9781468493993},
  abstract  = {This book is primarily a research document on the application of probability theory to the parameter estimation problem. The people who will be interested in this material are physicists, chemists, economists, and engineers who have to deal with data on a daily basis; consequently, we have included a great deal of introductory and tutorial material. Any person with the equivalent of the mathematics background required for the graduate-level study of physics should be able to follow the material contained in this book, though not without effort. In this work we apply probability theory to the problem of estimating parameters in rather general models. In particular when the model consists of a single stationary sinusoid we show that the direct application of probability theory will yield frequency estimates an order of magnitude better than a discrete Fourier transform in signal-to-noise of one. Latter, we generalize the problem and show that probability theory can separate two close frequencies long after the peaks in a discrete Fourier transform have merged.},
  file      = {:references/Bayesian Spectrum Analysis and Parameter Estimation/highlighted.pdf:PDF},
  groups    = {FAEFS},
  issn      = {9780387968711},
  keywords  = {Statistics},
  language  = {eng},
}

@Article{White1982,
  author    = {Halbert White},
  title     = {Maximum Likelihood Estimation of Misspecified Models},
  journal   = {Econometrica},
  year      = {1982},
  volume    = {50},
  number    = {1},
  pages     = {1--25},
  issn      = {00129682, 14680262},
  abstract  = {This paper examines the consequences and detection of model misspecification when using maximum likelihood techniques for estimation and inference. The quasi-maximum likelihood estimator (OMLE) converges to a well defined limit, and may or may not be consistent for particular parameters of interest. Standard tests (Wald, Lagrange Multiplier, or Likelihood Ratio) are invalid in the presence of misspecification, but more general statistics are given which allow inferences to be drawn robustly. The properties of the QMLE and the information matrix are exploited to yield several useful tests for model misspecification.},
  comment   = {Annotation that isn't being read properly, page 5:
"In the linear regression framework, omitting a relevant variable correlated with the included regressors will lead to inconsistent parameter estimates."},
  file      = {:references/Maximum Likelihood Estimation of Missspecified Models/highlighted.pdf:PDF},
  groups    = {FAEFS},
  publisher = {[Wiley, Econometric Society]},
  url       = {http://www.jstor.org/stable/1912526},
}

@Article{Scargle1982,
  author   = {{Scargle}, J.~D.},
  title    = {{Studies in astronomical time series analysis. II - Statistical aspects of spectral analysis of unevenly spaced data}},
  journal  = {Astrophysical Journal},
  year     = {1982},
  volume   = {263},
  pages    = {835-853},
  month    = dec,
  adsnote  = {Provided by the SAO/NASA Astrophysics Data System},
  adsurl   = {http://adsabs.harvard.edu/abs/1982ApJ...263..835S},
  doi      = {10.1086/160554},
  file     = {:references/Statistical Aspects of Spectral Analysis of Unevenly Spaced Data/highlighted.pdf:PDF},
  groups   = {FAEFS},
  keywords = {Astronomy, Signal Detection, Spectrum Analysis, Statistical Distributions, Time Series Analysis, Fourier Transformation, Frequency Response, Power Spectra, Signal To Noise Ratios},
}

@Article{Ferraz-Mello1981,
  author  = {{Ferraz-Mello}, S.},
  title   = {{Estimation of Periods from Unequally Spaced Observations}},
  journal = {Astronomical Journal},
  year    = {1981},
  volume  = {86},
  pages   = {619},
  month   = apr,
  adsnote = {Provided by the SAO/NASA Astrophysics Data System},
  adsurl  = {http://adsabs.harvard.edu/abs/1981AJ.....86..619F},
  doi     = {10.1086/112924},
  file    = {:references/Estimation of Periods from Unequally Spaced Observations/unhighlighted.pdf:PDF},
  groups  = {FAEFS},
}

@Article{Lomb1976,
  author   = {Lomb, N. R.},
  title    = {Least-squares frequency analysis of unequally spaced data},
  journal  = {Astrophysics and Space Science},
  year     = {1976},
  volume   = {39},
  number   = {2},
  pages    = {447--462},
  month    = {Feb},
  issn     = {1572-946X},
  abstract = {The statistical properties of least-squares frequency analysis of unequally spaced data are examined. It is shown that, in the least-squares spectrum of gaussian noise, the reduction in the sum of squares at a particular frequency is aX                  2                  2                 variable. The reductions at different frequencies are not independent, as there is a correlation between the height of the spectrum at any two frequencies,f1 andf2, which is equal to the mean height of the spectrum due to a sinusoidal signal of frequencyf1, at the frequencyf2. These correlations reduce the distortion in the spectrum of a signal affected by noise. Some numerical illustrations of the properties of least-squares frequency spectra are also given.},
  day      = {01},
  doi      = {10.1007/BF00648343},
  file     = {:references/Least-Squares Frequency Analysis of Unequally Spaced Data/highlighted.pdf:PDF},
  groups   = {FAEFS},
  url      = {https://doi.org/10.1007/BF00648343},
}

@Article{Deeming1975,
  author   = {Deeming, T. J.},
  title    = {Fourier analysis with unequally-spaced data},
  journal  = {Astrophysics and Space Science},
  year     = {1975},
  volume   = {36},
  number   = {1},
  pages    = {137--158},
  month    = {Aug},
  issn     = {1572-946X},
  abstract = {The general problems of Fourier and spectral analysis are discussed. A discrete Fourier transformF                  N                (v) of a functionf(t) is presented which (i) is defined for arbitrary data spacing; (ii) is equal to the convolution of the true Fourier transform off(t) with a spectral window. It is shown that the `pathology' of the data spacing, including aliasing and related effects, is all contained in the spectral window, and the properties of the spectral windows are examined for various kinds of data spacing. The results are applicable to power spectrum analysis of stochastic functions as well as to ordinary Fourier analysis of periodic or quasiperiodic functions.},
  day      = {01},
  doi      = {10.1007/BF00681947},
  file     = {:references/Fourier Analysis with Unequally-Spaced Data/highlighted.pdf:PDF},
  groups   = {FAEFS},
  url      = {https://doi.org/10.1007/BF00681947},
}

@Article{Epanechnikov1969,
  author  = {Epanechnikov, V.},
  journal = {Theory of Probability \& Its Applications},
  title   = {Non-Parametric Estimation of a Multivariate Probability Density},
  year    = {1969},
  number  = {1},
  pages   = {153-158},
  volume  = {14},
  comment = {Source of the Epanechnikov kernel, which has a 100% minimax efficiency when used in conjunction with a local linear smoother (Design-adaptive nonparametric regression (Fan, 1992)).},
  doi     = {10.1137/1114019},
  eprint  = {https://doi.org/10.1137/1114019},
  groups  = {FAEFS},
  url     = {https://doi.org/10.1137/1114019},
}

@Article{Schuster1898,
  author   = {Schuster, Arthur},
  title    = {On the investigation of hidden periodicities with application to a supposed 26 day period of meteorological phenomena},
  journal  = {Terrestrial Magnetism},
  year     = {1898},
  volume   = {3},
  number   = {1},
  pages    = {13-41},
  abstract = {1. Obvious and hidden periodicities. A variable quantity may show periodic changes which become obvious as soon as a sufficient record has been obtained; such are the semi-diurnal changes of the tides, or the eleven years recurrence of sunspot maxima. We may call these obvious periodicities. Most often, however, small periodic variations are hidden behind irregular fluctuations, and their investigation then becomes a matter of considerable difficulty.},
  doi      = {10.1029/TM003i001p00013},
  eprint   = {https://onlinelibrary.wiley.com/doi/pdf/10.1029/TM003i001p00013},
  file     = {:references/On the Investigation of Hidden Periodicities with Application to a Supposed 26 Day Period of Meteorological Phenomena/highlighted.pdf:PDF},
  groups   = {FAEFS},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1029/TM003i001p00013},
}

@Article{Hoerl1970,
  author    = {Arthur E. Hoerl and Robert W. Kennard},
  journal   = {Technometrics},
  title     = {Ridge Regression: Biased Estimation for Nonorthogonal Problems},
  year      = {1970},
  number    = {1},
  pages     = {55-67},
  volume    = {12},
  abstract  = {In multiple regression it is shown that parameter estimates based on minimum residual sum of squares have a high probability of being unsatisfactory, if not incorrect, if the prediction vectors are not orthogonal. Proposed is an estimation procedure based on adding small positive quantities to the diagonal of X′X. Introduced is the ridge trace, a method for showing in two dimensions the effects of nonorthogonality. It is then shown how to augment X′X to obtain biased estimates with smaller mean square error.},
  doi       = {10.1080/00401706.1970.10488634},
  eprint    = {https://www.tandfonline.com/doi/pdf/10.1080/00401706.1970.10488634},
  file      = {:/home/ryan/ownCloud/2018/Uni/ECE4094 and ECE4095 - Final Year Project/Research/references/Ridge Regression\: Biased Estimation for Nonorthogonal Problems/unhighlighted.pdf:PDF},
  groups    = {FAEFS},
  publisher = {Taylor \& Francis},
  url       = {https://www.tandfonline.com/doi/abs/10.1080/00401706.1970.10488634},
}

@Article{Schlax1992,
  author    = {Schlax, Michael G. and Chelton, Dudley B.},
  title     = {Frequency Domain Diagnostics for Linear Smoothers},
  journal   = {Journal of the American Statistical Association},
  year      = {1992},
  volume    = {87},
  number    = {420},
  pages     = {1070--1081},
  issn      = {0162-1459},
  abstract  = {Abstract Frequency domain analysis is used to examine estimates from linear smoothers operating on realizations of random fields over space and/or time. The estimates are expressed in terms of the Fourier transforms of the dependent variable and of the smoother weights. The latter is referred to as the equivalent transfer function. The data do not need to be evenly spaced to perform this analysis. The modulus of the equivalent transfer function characterizes the spectral content of an estimate and may reveal subtle sampling properties of the design. Frequency domain bias calculations are useful for comparing different smoothers and for assessing the resolution capabilities of a data set. These methods are used to compare six one-dimensional smoothers and analyze a complex three-dimensional example using data from a satellite altimeter.},
  file      = {:/home/ryan/ownCloud/2018/Uni/ECE4094 and ECE4095 - Final Year Project/Research/references/Frequency Domain Diagnostics for Linear Smoothers/unhighlighted.pdf:PDF},
  groups    = {FAEFS},
  keywords  = {Nonparametric Regression ; Smoothing ; Spatial Statistics ; Time Series},
  publisher = {Taylor \& Francis Group},
}

@Article{Hengartner2002,
  author   = {Hengartner, Nicolas W. and Wegkamp, Marten H. and Matzner-Løber, Eric},
  title    = {Bandwidth selection for local linear regression smoothers},
  journal  = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  year     = {2002},
  volume   = {64},
  number   = {4},
  pages    = {791 - 804},
  abstract = {Summary. The paper presents a general strategy for selecting the bandwidth of nonparametric regression estimators and specializes it to local linear regression smoothers. The procedure requires the sample to be divided into a training sample and a testing sample. Using the training sample we first compute a family of regression smoothers indexed by their bandwidths. Next we select the bandwidth by minimizing the empirical quadratic prediction error on the testing sample. The resulting bandwidth satisfies a finite sample oracle inequality which holds for all bounded regression functions. This permits asymptotically optimal estimation for nearly any regression function. The practical performance of the method is illustrated by a simulation study which shows good finite sample behaviour of our method compared with other bandwidth selection procedures.},
  doi      = {10.1111/1467-9868.00361},
  eprint   = {https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/1467-9868.00361},
  file     = {:/home/ryan/ownCloud/2018/Uni/ECE4094 and ECE4095 - Final Year Project/Research/references/Bandwidth Selection for Local Linear Regression/unhighlighted.pdf:PDF},
  groups   = {FAEFS},
  keywords = {Local linear regression smoother, Nonparametric regression, Oracle inequality, Universal bandwidth selection},
  url      = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/1467-9868.00361},
}

@Article{Giordano2008,
  author   = {F. Giordano and M.L. Parrella},
  title    = {Neural networks for bandwidth selection in local linear regression of time series},
  journal  = {Computational Statistics \& Data Analysis},
  year     = {2008},
  volume   = {52},
  number   = {5},
  pages    = {2435 - 2450},
  issn     = {0167-9473},
  abstract = {The problem of automatic bandwidth selection in nonparametric regression is considered when a local linear estimator is used to derive nonparametrically the unknown regression function. A plug-in method for choosing the smoothing parameter based on the use of the neural networks is presented. The method applies to dependent data generating processes with nonlinear autoregressive time series representation. The consistency of the method is shown in the paper, and a simulation study is carried out to assess the empirical performance of the procedure.},
  doi      = {https://doi.org/10.1016/j.csda.2007.08.013},
  file     = {:/home/ryan/ownCloud/2018/Uni/ECE4094 and ECE4095 - Final Year Project/Research/references/Neural Networks for Bandwidth Selection in Local Linear Regression of Time Series/unhighlighted.pdf:PDF},
  groups   = {FAEFS},
  keywords = {Nonparametric regression, Bandwidth selection, Derivative estimation, Dependent data, Local linear estimators, Neural networks},
  url      = {http://www.sciencedirect.com/science/article/pii/S0167947307003003},
}

@InBook{Harrell2015,
  pages     = {181--217},
  title     = {Overview of Maximum Likelihood Estimation},
  publisher = {Springer International Publishing},
  year      = {2015},
  author    = {Harrell, Frank E.},
  address   = {Cham},
  isbn      = {978-3-319-19425-7},
  abstract  = {In ordinary least squares multiple regression, the objective in fitting a model is to find the values of the unknown parameters that minimize the sum of squared errors of prediction. When the response variable is non-normal, polytomous, or not observed completely, one needs a more general objective function to optimize.},
  booktitle = {Regression Modeling Strategies: With Applications to Linear Models, Logistic and Ordinal Regression, and Survival Analysis},
  doi       = {10.1007/978-3-319-19425-7_9},
  groups    = {FAEFS},
}

@InBook{Tiku2006a,
  title     = {Noncentral F-Distribution},
  publisher = {American Cancer Society},
  year      = {2006},
  author    = {Tiku, M.},
  isbn      = {9780471667193},
  booktitle = {Encyclopedia of Statistical Sciences},
  doi       = {10.1002/0471667196.ess1799.pub2},
  eprint    = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/0471667196.ess1799.pub2},
  file      = {:/home/ryan/ownCloud/2018/Uni/ECE4094 and ECE4095 - Final Year Project/Research/references/Noncentral F-Distribution in Encyclopedia of Statistical Sciences/unhighlighted.pdf:PDF},
  groups    = {FAEFS},
  url       = {https://onlinelibrary.wiley.com/doi/abs/10.1002/0471667196.ess1799.pub2},
}

@InBook{Tiku2006,
  title     = {Noncentral Chi-Square Distribution},
  publisher = {American Cancer Society},
  year      = {2006},
  author    = {Tiku, M.},
  isbn      = {9780471667193},
  booktitle = {Encyclopedia of Statistical Sciences},
  doi       = {10.1002/0471667196.ess1798.pub2},
  eprint    = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/0471667196.ess1798.pub2},
  file      = {:/home/ryan/ownCloud/2018/Uni/ECE4094 and ECE4095 - Final Year Project/Research/references/Noncentral Chi-Square Distribution in Encyclopedia of Statistical Sciences/unhighlighted.pdf:PDF},
  groups    = {FAEFS},
  url       = {https://onlinelibrary.wiley.com/doi/abs/10.1002/0471667196.ess1798.pub2},
}

@Article{Lotkin1951,
  author    = {Lotkin, Max},
  title     = {On the Accuracy of Runge-Kutta's Method},
  journal   = {Mathematical Tables and Other Aids to Computation},
  year      = {1951},
  volume    = {5},
  number    = {35},
  pages     = {128--133},
  issn      = {08916837},
  file      = {:/home/ryan/ownCloud/2018/Uni/ECE4094 and ECE4095 - Final Year Project/Research/references/On the Accuracy of Runge-Kutta's Method/unhighlighted.pdf:PDF},
  groups    = {FAEFS},
  keywords  = {Mathematics -- Pure mathematics -- Calculus ; Mathematics -- Pure mathematics -- Calculus ; Mathematics -- Applied mathematics -- Statistics},
  language  = {eng},
  publisher = {The National Research Council},
}

@Article{Makridakis1982,
  author    = {Makridakis, S. and Andersen, A. and Carbone, R. and Fildes, R. and Hibon, M. and Lewandowski, R. and Newton, J. and Parzen, E. and Winkler, R.},
  title     = {The accuracy of extrapolation (time series) methods: Results of a forecasting competition},
  journal   = {Journal of Forecasting},
  year      = {1982},
  volume    = {1},
  number    = {2},
  pages     = {111--153},
  issn      = {0277-6693},
  abstract  = {In the last few decades many methods have become available for forecasting. As always, when alternatives exist, choices need to be made so that an appropriate forecasting method can be selected and used for the specific situation being considered. This paper reports the results of a forecasting competition that provides information to facilitate such choice. Seven experts in each of the 24 methods forecasted up to 1001 series for six up to eighteen time horizons. The results of the competition are presented in this paper whose purpose is to provide empirical evidence about found to exist among the various extrapolative (time series) methods used in the competition.},
  address   = {Chichester},
  file      = {:/home/ryan/ownCloud/2018/Uni/ECE4094 and ECE4095 - Final Year Project/Research/references/The Accuracy of Extrapolation (Time Series) Methods\: Results of a Forecasting Competition/unhighlighted.pdf:PDF},
  groups    = {FAEFS},
  keywords  = {Forecasting ; Time Series ; Evaluation ; Accuracy ; Comparison ; Empirical Study},
  language  = {eng},
  publisher = {John Wiley \& Sons, Ltd.},
}

@Article{Makridakis2000,
  author    = {Makridakis, Spyros and Hibon, Michèle},
  title     = {The M3-Competition: results, conclusions and implications},
  journal   = {International Journal of Forecasting},
  year      = {2000},
  volume    = {16},
  number    = {4},
  pages     = {451--476},
  issn      = {0169-2070},
  abstract  = {This paper describes the M3-Competition, the latest of the M-Competitions. It explains the reasons for conducting the competition and summarizes its results and conclusions. In addition, the paper compares such results/conclusions with those of the previous two M-Competitions as well as with those of other major empirical studies. Finally, the implications of these results and conclusions are considered, their consequences for both the theory and practice of forecasting are explored and directions for future research are contemplated.},
  file      = {:/home/ryan/ownCloud/2018/Uni/ECE4094 and ECE4095 - Final Year Project/Research/references/The M3 Competition\: Results, Conclusions and Implications/unhighlighted.pdf:PDF},
  groups    = {FAEFS},
  keywords  = {Comparative Methods — Time Series: Univariate ; Forecasting Competitions ; M-Competition ; Forecasting Methods, Forecasting Accuracy},
  language  = {eng},
  publisher = {Elsevier B.V.},
}

@Article{McCabe2011,
  author    = {Brendan P. M. McCabe and Gael M. Martin and David Harris},
  title     = {Efficient probabilistic forecasts for counts},
  journal   = {Journal of the Royal Statistical Society. Series B (Statistical Methodology)},
  year      = {2011},
  volume    = {73},
  number    = {2},
  pages     = {253--272},
  issn      = {13697412, 14679868},
  abstract  = {Efficient probabilistic forecasts of integer-valued random variables are derived. The optimality is achieved by estimating the forecast distribution non-parametrically over a given broad model class and proving asymptotic (non-parametric) efficiency in that setting. The method is developed within the context of the integer auto-regressive class of models, which is a suitable class for any count data that can be interpreted as a queue, stock, birth-and-death process or branching process. The theoretical proofs of asymptotic efficiency are supplemented by simulation results that demonstrate the overall superiority of the non-parametric estimator relative to a misspecified parametric alternative, in large but finite samples. The method is applied to counts of stock market iceberg orders. A subsampling method is used to assess sampling variation in the full estimated forecast distribution and a proof of its validity is given.},
  file      = {:references/Efficient Probabilistic Forecasts for Counts/highlighted.pdf:PDF;:references/Efficient Probabilistic Forecasts for Counts/Screen Shot 2019-03-05 at 11.19.42 am.png:PNG image;:references/Efficient Probabilistic Forecasts for Counts/Screen Shot 2019-03-05 at 11.20.30 am.png:PNG image;:references/Efficient Probabilistic Forecasts for Counts/Screen Shot 2019-03-05 at 11.23.35 am.png:PNG image;:references/Efficient Probabilistic Forecasts for Counts/Screen Shot 2019-03-05 at 11.24.13 am.png:PNG image;:references/Efficient Probabilistic Forecasts for Counts/Screen Shot 2019-03-05 at 11.26.07 am.png:PNG image},
  groups    = {Forecast Combinations, Frequentist},
  publisher = {[Royal Statistical Society, Wiley]},
}

@Article{Ng2013,
  author   = {Jason Ng and Catherine S. Forbes and Gael M. Martin and Brendan P.M. McCabe},
  title    = {Non-parametric estimation of forecast distributions in non-Gaussian, non-linear state space models},
  journal  = {International Journal of Forecasting},
  year     = {2013},
  volume   = {29},
  number   = {3},
  pages    = {411 - 430},
  issn     = {0169-2070},
  abstract = {The object of this paper is to produce non-parametric maximum likelihood estimates of forecast distributions in a general non-Gaussian, non-linear state space setting. The transition densities that define the evolution of the dynamic state process are represented in parametric form, but the conditional distribution of the non-Gaussian variable is estimated non-parametrically. The filtered and prediction distributions are estimated via a computationally efficient algorithm that exploits the functional relationship between the observed variable, the state variable and a measurement error with an invariant distribution. Simulation experiments are used to document the accuracy of the non-parametric method relative to both correctly and incorrectly specified parametric alternatives. In an empirical illustration, the method is used to produce sequential estimates of the forecast distribution of realized volatility on the S&P500 stock index during the recent financial crisis. A resampling technique for measuring sampling variation in the estimated forecast distributions is also demonstrated.},
  doi      = {https://doi.org/10.1016/j.ijforecast.2012.10.005},
  file     = {:references/Non-parametric Estimation of Forecast Distributions in Non-Gaussian, Non-linear State Space Models/highlighted.pdf:PDF;:references/Non-parametric Estimation of Forecast Distributions in Non-Gaussian, Non-linear State Space Models/Screenshots/0.png:PNG image;:references/Non-parametric Estimation of Forecast Distributions in Non-Gaussian, Non-linear State Space Models/Screenshots/1.png:PNG image;:references/Non-parametric Estimation of Forecast Distributions in Non-Gaussian, Non-linear State Space Models/Screenshots/2.png:PNG image},
  keywords = {Probabilistic forecasting, Non-Gaussian time series, Grid-based filtering, Penalized likelihood, Subsampling, Realized volatility},
  url      = {http://www.sciencedirect.com/science/article/pii/S0169207012001665},
}

@Article{Harris2018,
  author    = {Harris, David and Martin, Gael M and Perera, Indeewara and Poskitt, DS},
  title     = {Construction and visualization of confidence sets for frequentist distributional forecasts},
  journal   = {Journal of Computational and Graphical Statistics},
  year      = {2018},
  volume    = {28},
  number    = {1},
  pages     = {92--104},
  file      = {:references/Construction and Visualization of Confidence Sets for Frequentist Distributional Forecasts/highlighted.pdf:PDF;:references/Construction and Visualization of Confidence Sets for Frequentist Distributional Forecasts/0.PNG:PNG image;:references/Construction and Visualization of Confidence Sets for Frequentist Distributional Forecasts/1.PNG:PNG image;:references/Construction and Visualization of Confidence Sets for Frequentist Distributional Forecasts/3.PNG:PNG image;:references/Construction and Visualization of Confidence Sets for Frequentist Distributional Forecasts/2.PNG:PNG image;:references/Construction and Visualization of Confidence Sets for Frequentist Distributional Forecasts/4.PNG:PNG image},
  publisher = {Taylor \& Francis},
}

@Article{Claeskens2016,
  author    = {Claeskens, Gerda and Magnus, Jan R and Vasnev, Andrey L and Wang, Wendun},
  title     = {The Forecast Combination Puzzle: A Simple Theoretical Explanation},
  journal   = {International Journal of Forecasting},
  year      = {2016},
  volume    = {32},
  number    = {3},
  pages     = {754--762},
  file      = {:references/The Forecast Combination Puzzle a Simple Theoretical Explanation/highlighted.pdf:PDF},
  publisher = {Elsevier},
}

@Article{Efron1979,
  author    = {B. Efron},
  title     = {Bootstrap Methods: Another Look at the Jackknife},
  journal   = {The Annals of Statistics},
  year      = {1979},
  volume    = {7},
  number    = {1},
  pages     = {1--26},
  issn      = {00905364},
  abstract  = {We discuss the following problem: given a random sample X = (X1, X2, ⋯, Xn) from an unknown probability distribution F, estimate the sampling distribution of some prespecified random variable R(X, F), on the basis of the observed data x. (Standard jackknife theory gives an approximate mean and variance in the case R(X, F) = θ(F̂) - θ(F), θ some parameter of interest.) A general method, called the "bootstrap," is introduced, and shown to work satisfactorily on a variety of estimation problems. The jackknife is shown to be a linear approximation method for the bootstrap. The exposition proceeds by a series of examples: variance of the sample median, error rates in a linear discriminant analysis, ratio estimation, estimating regression parameters, etc.},
  file      = {:references/Bootstrap Methods Another Look at the Jackknife/unhighlighted.pdf:PDF;:references/Bootstrap Methods Another Look at the Jackknife/0.PNG:PNG image;:references/Bootstrap Methods Another Look at the Jackknife/1.PNG:PNG image;:references/Bootstrap Methods Another Look at the Jackknife/2.PNG:PNG image;:references/Bootstrap Methods Another Look at the Jackknife/3.PNG:PNG image;:references/Bootstrap Methods Another Look at the Jackknife/4.PNG:PNG image;:references/Bootstrap Methods Another Look at the Jackknife/5.PNG:PNG image;:references/Bootstrap Methods Another Look at the Jackknife/6.PNG:PNG image;:references/Bootstrap Methods Another Look at the Jackknife/7.PNG:PNG image;:references/Bootstrap Methods Another Look at the Jackknife/8.PNG:PNG image;:references/Bootstrap Methods Another Look at the Jackknife/9.PNG:PNG image},
  groups    = {Forecast Combinations, Frequentist},
  publisher = {Institute of Mathematical Statistics},
  url       = {http://www.jstor.org/stable/2958830},
}

@Article{Pauwels2016,
  author   = {Laurent L. Pauwels and Andrey L. Vasnev},
  title    = {A note on the estimation of optimal weights for density forecast combinations},
  journal  = {International Journal of Forecasting},
  year     = {2016},
  volume   = {32},
  number   = {2},
  pages    = {391 - 397},
  issn     = {0169-2070},
  abstract = {The problem of finding appropriate weights for combining several density forecasts is an important issue that is currently being debated in the forecast combination literature. A recent paper by Hall and Mitchell (2007) proposes that density forecasts be combined using the weights obtained from solving an optimization problem. This paper documents the properties of this optimization problem through a series of simulation experiments. When the number of forecasting periods is relatively small, the optimization problem often produces solutions that are dominated by a number of simple alternatives.},
  doi      = {https://doi.org/10.1016/j.ijforecast.2015.09.002},
  file     = {:references/A Note on the Estimation of Optimal Weights for Density Forecast Combinations/highlighted.pdf:PDF},
  groups   = {Forecast Combinations, Frequentist},
  keywords = {Forecast combination, Density forecast, Optimization, Optimal weight, Discrete choice models},
  url      = {http://www.sciencedirect.com/science/article/pii/S016920701500117X},
}

@Article{Opschoor2017,
  author    = {Opschoor, Anne and van Dijk, Dick and van der Wel, Michel},
  title     = {Combining Density Forecasts Using Focused Scoring Rules},
  journal   = {Journal of Applied Econometrics},
  year      = {2017},
  volume    = {32},
  number    = {7},
  pages     = {1298--1313},
  file      = {:references/Combining Density Forecasts using Focused Scoring Rules/highlighted.pdf:PDF;:references/Combining Density Forecasts using Focused Scoring Rules/0.PNG:PNG image;:references/Combining Density Forecasts using Focused Scoring Rules/1.PNG:PNG image;:references/Combining Density Forecasts using Focused Scoring Rules/2.PNG:PNG image;:references/Combining Density Forecasts using Focused Scoring Rules/3.PNG:PNG image},
  publisher = {Wiley Online Library},
}

@Article{Gneiting2011,
  author    = {Tilmann Gneiting and Roopesh Ranjan},
  journal   = {Journal of Business \& Economic Statistics},
  title     = {Comparing Density Forecasts Using Threshold- and Quantile-Weighted Scoring Rules},
  year      = {2011},
  number    = {3},
  pages     = {411-422},
  volume    = {29},
  abstract  = {We propose a method for comparing density forecasts that is based on weighted versions of the continuous ranked probability score. The weighting emphasizes regions of interest, such as the tails or the center of a variable’s range, while retaining propriety, as opposed to a recently developed weighted likelihood ratio test, which can be hedged. Threshold- and quantile-based decompositions of the continuous ranked probability score can be illustrated graphically and provide insight into the strengths and deficiencies of a forecasting method. We illustrate the use of the test and graphical tools in case studies on the Bank of England’s density forecasts of quarterly inflation rates in the United Kingdom, and probabilistic predictions of wind resources in the Pacific Northwest.},
  doi       = {10.1198/jbes.2010.08110},
  eprint    = {https://doi.org/10.1198/jbes.2010.08110},
  file      = {:references/Comparing Density Forecasts Using Threshold and Quantile Weighted Scoring Rules/highlighted.pdf:PDF;:references/Comparing Density Forecasts Using Threshold and Quantile Weighted Scoring Rules/0.PNG:PNG image;:references/Comparing Density Forecasts Using Threshold and Quantile Weighted Scoring Rules/1.PNG:PNG image;:references/Comparing Density Forecasts Using Threshold and Quantile Weighted Scoring Rules/2.PNG:PNG image;:references/Comparing Density Forecasts Using Threshold and Quantile Weighted Scoring Rules/3.PNG:PNG image;:references/Comparing Density Forecasts Using Threshold and Quantile Weighted Scoring Rules/4.PNG:PNG image;:references/Comparing Density Forecasts Using Threshold and Quantile Weighted Scoring Rules/5.PNG:PNG image;:references/Comparing Density Forecasts Using Threshold and Quantile Weighted Scoring Rules/6.PNG:PNG image;:references/Comparing Density Forecasts Using Threshold and Quantile Weighted Scoring Rules/7.PNG:PNG image;:references/Comparing Density Forecasts Using Threshold and Quantile Weighted Scoring Rules/8.PNG:PNG image},
  groups    = {Frequentist, Bayesian},
  publisher = {Taylor \& Francis},
  url       = {https://doi.org/10.1198/jbes.2010.08110},
}

@Article{Diks2011,
  author   = {Cees Diks and Valentyn Panchenko and van Dijk, Dick},
  title    = {Likelihood-Based Scoring Rules for Comparing Density Forecasts in Tails},
  journal  = {Journal of Econometrics},
  year     = {2011},
  volume   = {163},
  number   = {2},
  pages    = {215 - 230},
  issn     = {0304-4076},
  abstract = {We propose new scoring rules based on conditional and censored likelihood for assessing the predictive accuracy of competing density forecasts over a specific region of interest, such as the left tail in financial risk management. These scoring rules can be interpreted in terms of Kullbackâ€“Leibler divergence between weighted versions of the density forecast and the true density. Existing scoring rules based on weighted likelihood favor density forecasts with more probability mass in the given region, rendering predictive accuracy tests biased toward such densities. Using our novel likelihood-based scoring rules avoids this problem.},
  file     = {:references/Likelihood Based Scoring Rules for Comparing Density Forecasts in Tails/highlighted.pdf:PDF;:references/Likelihood Based Scoring Rules for Comparing Density Forecasts in Tails/0.PNG:PNG image;:references/Likelihood Based Scoring Rules for Comparing Density Forecasts in Tails/1.PNG:PNG image;:references/Likelihood Based Scoring Rules for Comparing Density Forecasts in Tails/2.PNG:PNG image},
  groups   = {Frequentist, Bayesian},
  keywords = {Density forecast evaluation, Scoring rules, Weighted likelihood ratio scores, Conditional likelihood, Censored likelihood, Risk management},
}

@Article{Jore2010,
  author   = {Jore, Anne Sofie and Mitchell, James and Vahey, Shaun P.},
  title    = {Combining forecast densities from VARs with uncertain instabilities},
  journal  = {Journal of Applied Econometrics},
  year     = {2010},
  volume   = {25},
  number   = {4},
  pages    = {621-634},
  abstract = {Abstract Recursive-weight forecast combination is often found to an ineffective method of improving point forecast accuracy in the presence of uncertain instabilities. We examine the effectiveness of this strategy for forecast densities using (many) vector autoregressive (VAR) and autoregressive (AR) models of output growth, inflation and interest rates. Our proposed recursive-weight density combination strategy, based on the recursive logarithmic score of the forecast densities, produces well-calibrated predictive densities for US real-time data by giving substantial weight to models that allow for structural breaks. In contrast, equal-weight combinations produce poorly calibrated forecast densities for Great Moderation data. Copyright © 2010 John Wiley \& Sons, Ltd.},
  doi      = {10.1002/jae.1162},
  eprint   = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/jae.1162},
  file     = {:references/Combining Forecast Densities from VARs with Uncertain Instabilities/highlighted.pdf:PDF;:references/Combining Forecast Densities from VARs with Uncertain Instabilities/0.PNG:PNG image},
  groups   = {Frequentist, Bayesian},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1002/jae.1162},
}

@TechReport{Pauwels2020,
  author      = {Laurent Pauwels and Peter Radchenko and Andrey L. Vasnev},
  title       = {{Higher moment constraints for predictive density combination}},
  institution = {Centre for Applied Macroeconomic Analysis, Crawford School of Public Policy, The Australian National University},
  year        = {2020},
  type        = {CAMA Working Papers},
  number      = {2020-45},
  month       = May,
  abstract    = {The majority of financial data exhibit asymmetry and heavy tails, which makes forecasting the entire density critically important. Recently, a forecast combination methodology has been developed to combine predictive densities. We show that combining individual predictive densities that are skewed and/or heavy-tailed results in significantly reduced skewness and kurtosis. We propose a solution to overcome this problem by deriving optimal log score weights under Higher-order Moment Constraints (HMC). The statistical properties of these weights, such as consistency and asymptotic distribution, are investigated theoretically and through a simulation study. An empirical application that uses the S\&P 500 daily index returns illustrates that the proposed HMC weight density combinations perform very well relative to other combination methods.},
  file        = {:references/Higher Moment Constraints for Predictive Density Combinations/unhighlighted.pdf:PDF},
  keywords    = {Forecast combinations; Predictive densities; Moment constraints; Financial data.},
}

@Article{Goetze1983,
  author   = {G{\"o}tze, F. and Hipp, C.},
  title    = {Asymptotic expansions for sums of weakly dependent random vectors},
  journal  = {Zeitschrift f{\"u}r Wahrscheinlichkeitstheorie und Verwandte Gebiete},
  year     = {1983},
  volume   = {64},
  number   = {2},
  pages    = {211--239},
  month    = {Jun},
  issn     = {1432-2064},
  abstract = {It is shown that formal Edgeworth expansions are valid for sums of weakly dependent random vectors. The error of approximation has ordero(n−(s−2)/2) if(i)the moments of orders+1 are uniformly bounded(ii)a conditional Cram{\'e}r-condition holds(iii)the random vectors can be approximated by other random vectors which satisfy a strong mixing condition and a Markov type condition.},
  day      = {01},
  doi      = {10.1007/BF01844607},
  groups   = {Frequentist, Forecast Combinations},
  url      = {https://doi.org/10.1007/BF01844607},
}

@Book{Hall1997,
  title     = {The Bootstrap and Edgeworth Expansion},
  publisher = {Springer New York},
  year      = {1997},
  author    = {Hall, P.},
  series    = {Springer Series in Statistics},
  isbn      = {9780387945088},
  groups    = {Forecast Combinations, Frequentist},
  lccn      = {91034951},
}

@Book{Davidson1994,
  title     = {Stochastic limit theory: An introduction for econometricians},
  publisher = {OUP Oxford},
  year      = {1994},
  author    = {Davidson, James},
}

@Article{Geyer1994,
  author    = {Geyer, Charles J.},
  title     = {On the Asymptotics of Constrained $M$-Estimation},
  journal   = {Ann. Statist.},
  year      = {1994},
  volume    = {22},
  number    = {4},
  pages     = {1993--2010},
  month     = {12},
  doi       = {10.1214/aos/1176325768},
  file      = {:references/On the Asymptotics of Constrained M-Estimation/On the Asymptotics of Constrained M-Estimation.pdf:PDF},
  fjournal  = {The Annals of Statistics},
  groups    = {Frequentist},
  publisher = {The Institute of Mathematical Statistics},
  url       = {https://doi.org/10.1214/aos/1176325768},
}

@Book{VanDerVaart1998,
  title     = {Asymptotic Statistics},
  publisher = {Cambridge University Press},
  year      = {1998},
  author    = {van der Vaart, A.W.},
  address   = {32 Avenue of the Americas, New York, NY 10013-2473, USA},
  groups    = {Frequentist},
  lccn      = {98015176},
}

@Book{Silvapulle2004,
  title     = {Constrained Statistical Inference: Order, Inequality, and Shape Constraints},
  publisher = {Wiley},
  year      = {2004},
  author    = {Silvapulle, M.J. and Sen, P.K.},
  series    = {Wiley Series in Probability and Statistics},
  isbn      = {9780471208273},
  groups    = {Frequentist, Model Selection Project},
  lccn      = {2004048075},
}

@Article{Gneiting2007,
  author    = {Tilmann Gneiting and Adrian E Raftery},
  journal   = {Journal of the American Statistical Association},
  title     = {Strictly Proper Scoring Rules, Prediction, and Estimation},
  year      = {2007},
  number    = {477},
  pages     = {359--378},
  volume    = {102},
  abstract  = {Scoring rules assess the quality of probabilistic forecasts, by assigning a numerical score based on the predictive distribution and on the event or value that materializes. A scoring rule is proper if the forecaster maximizes the expected score for an observation drawn from the distributionF if he or she issues the probabilistic forecast F, rather than G ≠ F. It is strictly proper if the maximum is unique. In prediction problems, proper scoring rules encourage the forecaster to make careful assessments and to be honest. In estimation problems, strictly proper scoring rules provide attractive loss and utility functions that can be tailored to the problem at hand. This article reviews and develops the theory of proper scoring rules on general probability spaces, and proposes and discusses examples thereof. Proper scoring rules derive from convex functions and relate to information measures, entropy functions, and Bregman divergences. In the case of categorical variables, we prove a rigorous version of the Savage representation. Examples of scoring rules for probabilistic forecasts in the form of predictive densities include the logarithmic, spherical, pseudospherical, and quadratic scores. The continuous ranked probability score applies to probabilistic forecasts that take the form of predictive cumulative distribution functions. It generalizes the absolute error and forms a special case of a new and very general type of score, the energy score. Like many other scoring rules, the energy score admits a kernel representation in terms of negative definite functions, with links to inequalities of Hoeffding type, in both univariate and multivariate settings. Proper scoring rules for quantile and interval forecasts are also discussed. We relate proper scoring rules to Bayes factors and to cross-validation, and propose a novel form of cross-validation known as random-fold cross-validation. A case study on probabilistic weather forecasts in the North American Pacific Northwest illustrates the importance of propriety. We note optimum score approaches to point and quantile estimation, and propose the intuitively appealing interval score as a utility function in interval estimation that addresses width as well as coverage.},
  file      = {:references/Strictly Proper Scoring Rules Prediction and Estimation/Strictly Proper Scoring Rules Prediction and Estimation.pdf:PDF},
  groups    = {Model Selection Project},
  publisher = {Taylor \& Francis},
}

@Book{Mammen1992,
  author    = {Mammen, E.},
  publisher = {Springer New York},
  title     = {When Does Bootstrap Work?: Asymptotic Results and Simulations},
  year      = {1992},
  isbn      = {9781461229506},
  series    = {Lecture Notes in Statistics},
  groups    = {ryan:6},
}

@Book{Hayashi2000,
  title     = {Econometrics},
  publisher = {Princeton University Press},
  year      = {2000},
  author    = {Hayashi, F.},
  isbn      = {9780691010182},
  lccn      = {00034665},
}

@Article{Giacomini2006,
  author    = {Giacomini, Raffaella and White, Halbert},
  title     = {Tests of Conditional Predictive Ability},
  journal   = {Econometrica},
  year      = {2006},
  volume    = {74},
  number    = {6},
  pages     = {1545--1578},
  file      = {:references/Tests of Conditional Predictive Ability/highlighted.pdf:PDF},
  publisher = {Wiley Online Library},
}

@Book{Bhatti2017,
  title     = {Econometric Analysis of Model Selection and Model Testing},
  publisher = {Taylor \& Francis},
  year      = {2017},
  author    = {Bhatti, M.I. and Al-Shanfari, H.},
  isbn      = {9781351941952},
  groups    = {Model Selection Project},
}

@Article{Diebold2015,
  author    = {Diebold, Francis X},
  title     = {Comparing predictive accuracy, twenty years later: A personal perspective on the use and abuse of Diebold--Mariano tests},
  journal   = {Journal of Business \& Economic Statistics},
  year      = {2015},
  volume    = {33},
  number    = {1},
  pages     = {1--1},
  file      = {:REFERE~1/COMPAR~2/COMPAR~1.PDF:PDF},
  groups    = {Model Selection Project},
  publisher = {Taylor \& Francis},
}

@Article{Mehmood2012,
  author    = {Mehmood, Tahir and Liland, Kristian Hovde and Snipen, Lars and S{\ae}b{\o}, Solve},
  title     = {A review of variable selection methods in partial least squares regression},
  journal   = {Chemometrics and Intelligent Laboratory Systems},
  year      = {2012},
  volume    = {118},
  pages     = {62--69},
  file      = {:references/A Review of Variable Selection Methods in Partial Least Squares Regression/A Review of Variable Selection Methods in Partial Least Squares Regression.pdf:PDF},
  groups    = {Model Selection Project},
  publisher = {Elsevier},
}

@Article{Chandrashekar2014,
  author    = {Chandrashekar, Girish and Sahin, Ferat},
  title     = {A survey on feature selection methods},
  journal   = {Computers \& Electrical Engineering},
  year      = {2014},
  volume    = {40},
  number    = {1},
  pages     = {16--28},
  file      = {:references/A Survey on Feature Selection Methods/A Survey on Feature Selection Methods.pdf:PDF},
  groups    = {Model Selection Project},
  publisher = {Elsevier},
}

@Article{West1996,
  author    = {West, Kenneth D},
  title     = {Asymptotic Inference About Predictive Ability},
  journal   = {Econometrica},
  year      = {1996},
  pages     = {1067--1084},
  file      = {:references/Asymptotic Inference about Predictive Ability/Asymptotic Inference about Predictive Ability.pdf:PDF},
  groups    = {Model Selection Project},
  publisher = {JSTOR},
}

@Article{Diebold1995,
  author    = {Diebold, Francis X and Mariano, Robert S},
  title     = {Comparing Predictive Accuracy},
  journal   = {Journal of Business \& Economic Statistics},
  year      = {1995},
  volume    = {13},
  number    = {3},
  pages     = {253--263},
  file      = {:references/Comparing Predictive Accuracy/Comparing Predictive Accuracy.pdf:PDF},
  groups    = {Model Selection Project},
  publisher = {Taylor \& Francis},
}

@Article{Inoue2006,
  author    = {Inoue, Atsushi and Kilian, Lutz},
  title     = {On the selection of forecasting models},
  journal   = {Journal of Econometrics},
  year      = {2006},
  volume    = {130},
  number    = {2},
  pages     = {273--306},
  file      = {:references/On the Selection of Forecasting Models/On the Selection of Forecasting Models.pdf:PDF},
  groups    = {Model Selection Project},
  publisher = {Elsevier},
}

@Article{Kadane2004,
  author    = {Kadane, Joseph B and Lazar, Nicole A},
  title     = {Methods and criteria for model selection},
  journal   = {Journal of the American statistical Association},
  year      = {2004},
  volume    = {99},
  number    = {465},
  pages     = {279--290},
  file      = {:references/Methods and Criteria for Model Selection/Methods and Criteria for Model Selection.pdf:PDF},
  groups    = {Model Selection Project},
  publisher = {Taylor \& Francis},
}

@Article{Mills1992,
  author    = {Mills, Jeffrey A and Prasad, Kislaya},
  title     = {A comparison of model selection criteria},
  journal   = {Econometric reviews},
  year      = {1992},
  volume    = {11},
  number    = {2},
  pages     = {201--234},
  file      = {:references/A Comparison of Model Selection Criteria/A Comparison of Model Selection Criteria.pdf:PDF},
  groups    = {Model Selection Project},
  publisher = {Taylor \& Francis},
}

@Article{Domowitz1982,
  author    = {Domowitz, Ian and White, Halbert},
  title     = {Misspecified models with dependent observations},
  journal   = {Journal of Econometrics},
  year      = {1982},
  volume    = {20},
  number    = {1},
  pages     = {35--58},
  file      = {:references/Misspecified Models with Dependent Observations/Misspecified Models with Dependent Observations.pdf:PDF},
  groups    = {Model Selection Project},
  publisher = {Elsevier},
}

@Article{Bates1985,
  author    = {Bates, Charles and White, Halbert},
  title     = {A unified theory of consistent estimation for parametric models},
  journal   = {Econometric Theory},
  year      = {1985},
  volume    = {1},
  number    = {2},
  pages     = {151--178},
  file      = {:references/A Unified Theory of Consistent Estimation for Parametric Models/A Unified Theory of Consistent Estimation for Parametric Models.pdf:PDF},
  groups    = {Model Selection Project},
  publisher = {Cambridge University Press},
}

@Article{Ranjan2010,
  author    = {Ranjan, Roopesh and Gneiting, Tilmann},
  title     = {Combining Probability Forecasts},
  journal   = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  year      = {2010},
  volume    = {72},
  number    = {1},
  pages     = {71--91},
  file      = {:references/Combining Probability Forecasts/Combining Probability Forecasts.pdf:PDF},
  publisher = {Wiley Online Library},
}

@Article{Gneiting2013,
  author    = {Gneiting, Tilmann and Ranjan, Roopesh},
  title     = {Combining Predictive Distributions},
  journal   = {Electronic Journal of Statistics},
  year      = {2013},
  volume    = {7},
  pages     = {1747--1782},
  file      = {:references/Combining Predictive Distributions/Combining Predictive Distributions.pdf:PDF},
  publisher = {The Institute of Mathematical Statistics and the Bernoulli Society},
}

@Book{Hastie2015,
  title     = {Statistical learning with sparsity: the lasso and generalizations},
  publisher = {Chapman and Hall/CRC},
  year      = {2015},
  author    = {Hastie, Trevor and Tibshirani, Robert and Wainwright, Martin},
  file      = {:references/Statistical Learning with Sparsity/Statistical Learning with Sparsity.pdf:PDF},
  groups    = {Model Selection Project},
}

@Article{huebner2000asymptotic,
  author    = {Huebner, M and Lototsky, S},
  title     = {Asymptotic analysis of the sieve estimator for a class of parabolic SPDEs},
  journal   = {Scandinavian journal of statistics},
  year      = {2000},
  volume    = {27},
  number    = {2},
  pages     = {353--370},
  file      = {:references/Asymptotic Analysis of the Sieve Estimator for a Class of Parabolic SPDEs/Asymptotic Analysis of the Sieve Estimator for a Class of Parabolic SPDEs.pdf:PDF},
  groups    = {Model Selection Project},
  publisher = {Wiley Online Library},
}

@Article{hahn2018nonparametric,
  author    = {Hahn, Jinyong and Liao, Zhipeng and Ridder, Geert},
  title     = {Nonparametric two-step sieve M estimation and inference},
  journal   = {Econometric Theory},
  year      = {2018},
  volume    = {34},
  number    = {6},
  pages     = {1281--1324},
  file      = {:references/Nonparametric Two-Step Sieve M Estimation and Inference/Nonparametric Two-Step Sieve M Estimation and Inference.pdf:PDF},
  groups    = {Model Selection Project},
  publisher = {Cambridge University Press},
}

@Article{bierens2014consistency,
  author    = {Bierens, Herman J},
  title     = {Consistency and asymptotic normality of sieve ML estimators under low-level conditions},
  journal   = {Econometric Theory},
  year      = {2014},
  volume    = {30},
  number    = {5},
  pages     = {1021--1076},
  file      = {:references/Consistency and Asymptotic Normality of Sieve ML Estimators Under Low-Level Conditions/Consistency and Asymptotic Normality of Sieve ML Estimators Under Low-Level Conditions.pdf:PDF},
  groups    = {Model Selection Project},
  publisher = {Cambridge University Press},
}

@Book{Hogg2013,
  title     = {Introduction to Mathematical Statistics},
  publisher = {Pearson},
  year      = {2013},
  author    = {Hogg, R.V. and McKean, J.W. and Craig, A.T.},
  series    = {Always learning},
  isbn      = {9780321795434},
  lccn      = {2004054692},
}

@Article{Andrews2005,
  author    = {Andrews, Donald WK},
  title     = {Higher-order improvements of the parametric bootstrap for Markov processes},
  journal   = {Identification and Inference for Econometric Models: Essays in Honor of Thomas Rothenberg},
  year      = {2005},
  pages     = {171--215},
  publisher = {Cambridge University Press},
}

@Book{Bradley2007,
  title     = {Introduction to strong mixing conditions},
  publisher = {Kendrick press},
  year      = {2007},
  author    = {Bradley, Richard C},
}

@Misc{Bengs2019,
  author        = {Viktor Bengs and Hajo Holzmann},
  title         = {Uniform approximation in classical weak convergence theory},
  year          = {2019},
  archiveprefix = {arXiv},
  eprint        = {1903.09864},
  file          = {:references/Uniform Approximation in Classical Weak Convergence Theory/Uniform Approximation in Classical Weak Convergence Theory.pdf:PDF},
  primaryclass  = {math.PR},
}

@Article{Heyde1970,
  author    = {Heyde, CC and Brown, BM and others},
  title     = {On the Departure from Normality of a Certain Class of Martingales},
  journal   = {The Annals of Mathematical Statistics},
  year      = {1970},
  volume    = {41},
  number    = {6},
  pages     = {2161--2165},
  file      = {:references/On the Departure from Normality of a Certain Class of Martingales.pdf/On the Departure from Normality of a Certain Class of Martingales.pdf:PDF},
  publisher = {Institute of Mathematical Statistics},
}

@Article{Pollard1991,
  author    = {Pollard, David},
  title     = {Asymptotics for least absolute deviation regression estimators},
  journal   = {Econometric Theory},
  year      = {1991},
  volume    = {7},
  number    = {2},
  pages     = {186--199},
  file      = {:references/Asymptotics for Least Absolute Deviation Regression Estimators/Asymptotics for Least Absolute Deviation Regression Estimators.pdf:PDF},
  publisher = {Cambridge University Press},
}

@Book{Rockafellar1970,
  title     = {Convex analysis},
  publisher = {Princeton university press},
  year      = {1970},
  author    = {Rockafellar, R Tyrrell},
  number    = {28},
}

@Article{Sweeting1980,
  author    = {Sweeting, Trevor J},
  title     = {Uniform asymptotic normality of the maximum likelihood estimator},
  journal   = {The Annals of Statistics},
  year      = {1980},
  pages     = {1375--1381},
  file      = {:references/Uniform Asymptotic Normality of the Maximum Likelihood Estimator/Uniform Asymptotic Normality of the Maximum Likelihood Estimator.pdf:PDF},
  publisher = {JSTOR},
}

@Article{Douc2004,
  author    = {Douc, Randal and Moulines, Eric and Ryd{\'e}n, Tobias and others},
  title     = {Asymptotic properties of the maximum likelihood estimator in autoregressive models with Markov regime},
  journal   = {The Annals of statistics},
  year      = {2004},
  volume    = {32},
  number    = {5},
  pages     = {2254--2304},
  file      = {:references/Asymptotic Properties of the Maximum Likelihood Estimator in Autoregressive Models with Markov Regime/Asymptotic Properties of the Maximum Likelihood Estimator in Autoregressive Models with Markov Regime.pdf:PDF},
  publisher = {Institute of Mathematical Statistics},
}

@Article{Hernandez-Lerma2000,
  author    = {Hern{\'a}ndez-Lerma, On{\'e}simo and Lasserre, Jean B},
  title     = {Fatou's lemma and Lebesgue's convergence theorem for measures},
  journal   = {International Journal of Stochastic Analysis},
  year      = {2000},
  volume    = {13},
  number    = {2},
  pages     = {137--146},
  file      = {:references/Fatous Lemma and Lebesgues Convergence Theorem for Measures/Fatous Lemma and Lebesgues Convergence Theorem for Measures.pdf:PDF},
  publisher = {Hindawi},
}

@Article{Serfozo1982,
  author    = {Serfozo, Richard},
  title     = {Convergence of Lebesgue integrals with varying measures},
  journal   = {Sankhy{\=a}: The Indian Journal of Statistics, Series A},
  year      = {1982},
  pages     = {380--402},
  file      = {:references/Convergence of Lebesgue Integrals with Varying Measures/Convergence of Lebesgue Integrals with Varying Measures.pdf:PDF},
  publisher = {JSTOR},
}

@Article{Wong2001,
  author    = {Wong, Chun Shan and Li, Wai Keung},
  title     = {On a mixture autoregressive conditional heteroscedastic model},
  journal   = {Journal of the American Statistical Association},
  year      = {2001},
  volume    = {96},
  number    = {455},
  pages     = {982--995},
  file      = {:references/On a Mixture Autoregressive Conditional Heteroscedastic Model/On a Mixture Autoregressive Conditional Heteroscedastic Model.pdf:PDF},
  publisher = {Taylor \& Francis},
}

@Article{Okui2010,
  author    = {Okui, Ryo},
  title     = {Asymptotically unbiased estimation of autocovariances and autocorrelations with long panel data},
  journal   = {Econometric Theory},
  year      = {2010},
  volume    = {26},
  number    = {5},
  pages     = {1263--1304},
  file      = {:references/Asymptotically Unbiased Estimation of Autocovariances and Autocorrelations with Long Panel Data/Asymptotically Unbiased Estimation of Autocovariances and Autocorrelations with Long Panel Data.pdf:PDF},
  publisher = {Cambridge University Press},
}

@Book{Silverman1986,
  title     = {Density estimation for statistics and data analysis},
  publisher = {CRC press},
  year      = {1986},
  author    = {Silverman, Bernard W},
  volume    = {26},
  file      = {:references/Density Estimation for Statistics and Data Analysis/The Kernel Method for Univariate Data.pdf:PDF},
}

@Book{Billingsley1999,
  title     = {Convergence of probability measures},
  publisher = {Wiley},
  year      = {1999},
  author    = {Billingsley, Patrick},
  series    = {Wiley series in probability and statistics. Probability and statistics},
  address   = {New York},
  edition   = {2nd ed.},
  isbn      = {0471197459},
  abstract  = {"In this new edition, Patrick Billingsley updates his classic work Convergence of Probability Measures to reflect developments of the past thirty years. Dr. Billingsley presents a clear, precise, up-to-date account of probability limit theory in metric spaces. He incorporates many examples and applications that illustrate the power and utility of this theory in a range of disciplines - from analysis and number theory to statistics, engineering, economics, and population biology."--BOOK JACKET.},
  issn      = {0-471-19745-9},
  keywords  = {Probability measures; Metric spaces; Convergence},
  language  = {eng},
  lccn      = {99030372},
}

@Article{Topsoe1967,
  author    = {Tops{\o}e, Flemming},
  title     = {On the connection between P-continuity and P-uniformity in weak convergence},
  journal   = {Theory of Probability \& Its Applications},
  year      = {1967},
  volume    = {12},
  number    = {2},
  pages     = {241--250},
  file      = {:references/On the Connection Between P-Continuity and P-Uniformity in Weak Convergence/On the Connection Between P-Continuity and P-Uniformity in Weak Convergence.pdf:PDF},
  publisher = {SIAM},
}

@Article{Billingsley1967,
  author    = {Billingsley, Patrick and Tops{\o}e, Flemming},
  title     = {Uniformity in weak convergence},
  journal   = {Zeitschrift f{\"u}r Wahrscheinlichkeitstheorie und verwandte Gebiete},
  year      = {1967},
  volume    = {7},
  number    = {1},
  pages     = {1--16},
  file      = {:references/Uniformity in Weak Convergence/Uniformity in Weak Convergence.pdf:PDF},
  publisher = {Springer},
}

@Article{Liang2011,
  author    = {Liang, Hua and Zou, Guohua and Wan, Alan TK and Zhang, Xinyu},
  title     = {Optimal weight choice for frequentist model average estimators},
  journal   = {Journal of the American Statistical Association},
  year      = {2011},
  volume    = {106},
  number    = {495},
  pages     = {1053--1066},
  file      = {:references/Optimal Weight Choice for Frequentist Model Average Estimators/Optimal Weight Choice for Frequentist Model Average Estimators.pdf:PDF},
  publisher = {Taylor \& Francis},
}

@Article{Elliott2011,
  author  = {Elliott, Graham},
  title   = {Averaging and the optimal combination of forecasts},
  journal = {Manuscript, Department of Economics, UCSD},
  year    = {2011},
  file    = {:references/Averaging and the Optimal Combination of Forecasts/Averaging and the Optimal Combination of Forecasts.pdf:PDF},
}

@Article{Chan2018,
  author    = {Chan, Felix and Pauwels, Laurent L},
  title     = {Some Theoretical Results on Forecast Combinations},
  journal   = {International Journal of Forecasting},
  year      = {2018},
  volume    = {34},
  number    = {1},
  pages     = {64--74},
  file      = {:references/Some Theoretical Results on Forecast Combinations/Some Theoretical Results on Forecast Combinations.pdf:PDF},
  publisher = {Elsevier},
}

@Article{Stock2004,
  author    = {Stock, James H and Watson, Mark W},
  title     = {Combination Forecasts of Output Growth in a Seven-Country Data Set},
  journal   = {Journal of Forecasting},
  year      = {2004},
  volume    = {23},
  number    = {6},
  pages     = {405--430},
  file      = {:references/Combination Forecasts of Output Growth in a Seven-Country Data Set/Combination Forecasts of Output Growth in a Seven-Country Data Set.pdf:PDF},
  publisher = {Wiley Online Library},
}

@Article{Hsiao2014,
  author    = {Hsiao, Cheng and Wan, Shui Ki},
  title     = {Is There an Optimal Forecast Combination?},
  journal   = {Journal of Econometrics},
  year      = {2014},
  volume    = {178},
  pages     = {294--309},
  file      = {:references/Is There An Optimal Forecast Combination/Is There An Optimal Forecast Combination.pdf:PDF},
  publisher = {Elsevier},
}

@Article{Elliott2017,
  author    = {Elliott, Graham},
  title     = {Forecast Combination When Outcomes are Difficult to Predict},
  journal   = {Empirical Economics},
  year      = {2017},
  volume    = {53},
  number    = {1},
  pages     = {7--20},
  file      = {:references/Forecast Combination when Outcomes are Difficult to Predict/Forecast Combination when Outcomes are Difficult to Predict.pdf:PDF},
  publisher = {Springer},
}

@Article{Clemen1989,
  author    = {Clemen, Robert T},
  title     = {Combining Forecasts: A Review and Annotated Bibliography},
  journal   = {International Journal of Forecasting},
  year      = {1989},
  volume    = {5},
  number    = {4},
  pages     = {559--583},
  file      = {:references/Combining Forecasts - A Review and Annotated Bibliography/Combining Forecasts - A Review and Annotated Bibliography.pdf:PDF},
  publisher = {Elsevier},
}

@Article{Smith2009,
  author    = {Smith, Jeremy and Wallis, Kenneth F},
  title     = {A Simple Explanation of the Forecast Combination Puzzle},
  journal   = {Oxford Bulletin of Economics and Statistics},
  year      = {2009},
  volume    = {71},
  number    = {3},
  pages     = {331--355},
  file      = {:references/A Simple Explanation of the Forecast Combination Puzzle/A Simple Explanation of the Forecast Combination Puzzle.pdf:PDF},
  publisher = {Wiley Online Library},
}

@Article{Bates1969,
  author    = {Bates, John M and Granger, Clive WJ},
  title     = {The Combination of Forecasts},
  journal   = {Journal of the Operational Research Society},
  year      = {1969},
  volume    = {20},
  number    = {4},
  pages     = {451--468},
  file      = {:references/The Combination of Forecasts/The Combination of Forecasts.pdf:PDF},
  publisher = {Taylor \& Francis},
}

@InCollection{Timmermann2006,
  author    = {Allan Timmermann},
  title     = {Forecast Combinations},
  booktitle = {Handbook of Economic Forecasting},
  publisher = {Elsevier},
  year      = {2006},
  editor    = {G. Elliott and C.W.J. Granger and A. Timmermann},
  volume    = {1},
  chapter   = {4},
  pages     = {135-196},
  address   = {Radarweg 29, Amsterdam 1043 NX, Netherlands},
  doi       = {https://doi.org/10.1016/S1574-0706(05)01004-9},
  issn      = {1574-0706},
  keywords  = {forecast combinations, pooling and trimming, shrinkage methods, model misspecification, diversification gains},
}

@Article{Makridakis2020,
  author    = {Makridakis, Spyros and Spiliotis, Evangelos and Assimakopoulos, Vassilios},
  title     = {The M4 Competition: 100,000 Time Series and 61 Forecasting Methods},
  journal   = {International Journal of Forecasting},
  year      = {2020},
  volume    = {36},
  number    = {1},
  pages     = {54--74},
  file      = {:references/The M4 Competition - 100000 Time Series and 61 Forecasting Methods/The M4 Competition - 100000 Time Series and 61 Forecasting Methods.pdf:PDF},
  publisher = {Elsevier},
}

@Article{Makridakis2018,
  author    = {Makridakis, Spyros and Spiliotis, Evangelos and Assimakopoulos, Vassilios},
  title     = {The M4 Competition: Results, Findings, Conclusion and Way Forward},
  journal   = {International Journal of Forecasting},
  year      = {2018},
  volume    = {34},
  number    = {4},
  pages     = {802--808},
  file      = {:references/The M4 Competition - Results Findings Conclusion and Way Forward/The M4 Competition - Results Findings Conclusion and Way Forward.pdf:PDF},
  publisher = {Elsevier},
}

@Article{Jacod2018,
  author    = {Jacod, Jean and S{\o}rensen, Michael},
  title     = {A review of asymptotic theory of estimating functions},
  journal   = {Statistical Inference for Stochastic Processes},
  year      = {2018},
  volume    = {21},
  number    = {2},
  pages     = {415--434},
  file      = {:references/A Review of Asymptotic Theory of Estimating Functions/A Review of Asymptotic Theory of Estimating Functions.pdf:PDF},
  publisher = {Springer},
}

@Article{Krzysztofowicz1999,
  author  = {Krzysztofowicz, Roman and Sigrest, Ashley A},
  title   = {Comparative verification of guidance and local quantitative precipitation forecasts: Calibration analyses},
  journal = {Weather and Forecasting},
  year    = {1999},
  volume  = {14},
  number  = {3},
  pages   = {443--454},
}

@Article{BjornarBremnes2004,
  author  = {Bj{\o}rnar Bremnes, John},
  title   = {Probabilistic forecasts of precipitation in terms of quantiles using NWP model output},
  journal = {Monthly Weather Review},
  year    = {2004},
  volume  = {132},
  number  = {1},
  pages   = {338--347},
}

@Article{Matheson1976,
  author    = {Matheson, James E and Winkler, Robert L},
  title     = {Scoring rules for continuous probability distributions},
  journal   = {Management science},
  year      = {1976},
  volume    = {22},
  number    = {10},
  pages     = {1087--1096},
  publisher = {INFORMS},
}

@Article{Hersbach2000,
  author  = {Hersbach, Hans},
  title   = {Decomposition of the continuous ranked probability score for ensemble prediction systems},
  journal = {Weather and Forecasting},
  year    = {2000},
  volume  = {15},
  number  = {5},
  pages   = {559--570},
}

@Article{Akaike1974,
  author    = {Akaike, Hirotugu},
  title     = {A new look at the statistical model identification},
  journal   = {IEEE Transactions on Automatic Control},
  year      = {1974},
  volume    = {19},
  number    = {6},
  pages     = {716--723},
  file      = {:references/A New Look at the Statistical Model Identification/A New Look at the Statistical Model Identification.pdf:PDF},
  publisher = {Ieee},
}

@Article{Andrews2006,
  author    = {Andrews, Donald WK and Lieberman, Offer and Marmer, Vadim},
  title     = {Higher-order improvements of the parametric bootstrap for long-memory Gaussian processes},
  journal   = {Journal of Econometrics},
  year      = {2006},
  volume    = {133},
  number    = {2},
  pages     = {673--702},
  publisher = {Elsevier},
}

@Article{Wong1998,
  author    = {Wong, Chun-shan},
  title     = {Statistical inference for some nonlinear time series models},
  journal   = {香港大學學位論文},
  year      = {1998},
  pages     = {1--0},
  publisher = {香港大學},
}

@Article{Wong2000,
  author    = {Wong, Chun Shan and Li, Wai Keung},
  title     = {On a mixture autoregressive model},
  journal   = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  year      = {2000},
  volume    = {62},
  number    = {1},
  pages     = {95--115},
  publisher = {Wiley Online Library},
}

@Article{Hall2007,
  author    = {Hall, Stephen G and Mitchell, James},
  title     = {Combining Density Forecasts},
  journal   = {International Journal of Forecasting},
  year      = {2007},
  volume    = {23},
  number    = {1},
  pages     = {1--13},
  file      = {:references/Combining Density Forecasts/Combining Density Forecasts.pdf:PDF},
  publisher = {Elsevier},
}

@Article{Geweke2011,
  author    = {Geweke, John and Amisano, Gianni},
  title     = {Optimal Prediction Pools},
  journal   = {Journal of Econometrics},
  year      = {2011},
  volume    = {164},
  number    = {1},
  pages     = {130--141},
  file      = {:references/Optimal Prediction Pools/Optimal Prediction Pools.pdf:PDF},
  publisher = {Elsevier},
}

@Article{Krueger2013,
  author  = {Kr{\"u}ger, Fabian},
  title   = {Jensen’s inequality and the success of linear prediction pools},
  journal = {Work. Pap., Dep. Econ., Univ. Konstanz, Konstanz, Ger. Google Scholar Article Location},
  year    = {2013},
  file    = {:references/Jensens Inequality and the Success of Linear Prediction Pools/unhighlighted.pdf:PDF},
}

@Article{Loaiza-Maya2021,
  author    = {Loaiza-Maya, Ruben and Martin, Gael M and Frazier, David T},
  journal   = {Journal of Applied Econometrics},
  title     = {Focused Bayesian Prediction},
  year      = {2021},
  number    = {5},
  pages     = {517--543},
  volume    = {36},
  file      = {:references/Focused Bayesian Prediction/unhighlighted.pdf:PDF},
  publisher = {Wiley Online Library},
}

@Article{Stone1961,
  author  = {Stone, Mervyn},
  title   = {The Linear Opinion Pool},
  journal = {The Annals of Mathematical Statistics},
  year    = {1961},
  volume  = {32},
  pages   = {1339--1342},
  file    = {:references/The Linear Opinion Pool/The Linear Opinion Pool.pdf:PDF},
}

@Article{Carletti2020,
  author  = {Carletti, Timoteo and Fanelli, Duccio and Piazza, Francesco},
  title   = {COVID-19: The unreasonable effectiveness of simple models},
  journal = {arXiv preprint arXiv:2005.11085},
  year    = {2020},
  file    = {:references/COVID-19 - The Unreasonabl Effectiveness of Simple Models/COVID-19 - The Unreasonabl Effectiveness of Simple Models.pdf:PDF},
}

@Article{Baek2020,
  author  = {Baek, Jackie and Farias, Vivek F and Georgescu, Andreea and Levi, Retsef and Peng, Tianyi and Sinha, Deeksha and Wilde, Joshua and Zheng, Andrew},
  title   = {The Limits to Learning an SIR Process: Granular Forecasting for Covid-19},
  journal = {arXiv preprint arXiv:2006.06373},
  year    = {2020},
  file    = {:references/The Limits to Learning an SIR Process - Granular Forecasting for Covid-19/The Limits to Learning an SIR Process - Granular Forecasting for Covid-19.pdf:PDF},
}

@Article{Petropoulos2020,
  author    = {Petropoulos, Fotios and Makridakis, Spyros},
  title     = {Forecasting the novel coronavirus COVID-19},
  journal   = {PloS one},
  year      = {2020},
  volume    = {15},
  number    = {3},
  pages     = {e0231236},
  file      = {:references/Forecasting the Novel Coronavirus COVID-19/Forecasting the Novel Coronavirus COVID-19.pdf:PDF},
  publisher = {Public Library of Science San Francisco, CA USA},
}

@Article{Chakraborty2020,
  author    = {Chakraborty, Tanujit and Ghosh, Indrajit},
  title     = {Real-time forecasts and risk assessment of novel coronavirus (COVID-19) cases: A data-driven analysis},
  journal   = {Chaos, Solitons \& Fractals},
  year      = {2020},
  pages     = {109850},
  file      = {:references/Real-Time Forecasts and Risk Assessment of Novel Coronavirus (COVID-19) Cases - A Data-Drive Analysis/Real-Time Forecasts and Risk Assessment of Novel Coronavirus (COVID-19) Cases - A Data-Drive Analysis.pdf:PDF},
  publisher = {Elsevier},
}

@Article{Bowman2020,
  author  = {Bowman, VE and Silk, DS and Dalrymple, U and Woods, DC},
  title   = {Uncertainty quantification for epidemiological forecasts of COVID-19 through combinations of model predictions},
  journal = {arXiv preprint arXiv:2006.10714},
  year    = {2020},
  file    = {:references/Uncertainty Quantification for Epidemiological Forecasts of COVID-19 Through Combinations of Model Predictions/Uncertainty Quantification for Epidemiological Forecasts of COVID-19 Through Combinations of Model Predictions.pdf:PDF},
}

@Article{Dong2020,
  author    = {Dong, Ensheng and Du, Hongru and Gardner, Lauren},
  title     = {An interactive web-based dashboard to track COVID-19 in real time},
  journal   = {The Lancet Infectious Diseases},
  year      = {2020},
  volume    = {20},
  number    = {5},
  pages     = {533--534},
  file      = {:references/An Interactive Web-Based Dashboard to Track COVID-19 in Real Time/An Interactive Web-Based Dashboard to Track COVID-19 in Real Time.pdf:PDF},
  publisher = {Elsevier},
}

@Article{Hyndman2002,
  author    = {Hyndman, Rob J and Koehler, Anne B and Snyder, Ralph D and Grose, Simone},
  title     = {A state space framework for automatic forecasting using exponential smoothing methods},
  journal   = {International Journal of forecasting},
  year      = {2002},
  volume    = {18},
  number    = {3},
  pages     = {439--454},
  file      = {:references/A State Space Framework for Auotmatic Forecasting using Exponential Smoothing Methods/A State Space Framework for Auotmatic Forecasting using Exponential Smoothing Methods.pdf:PDF},
  publisher = {Elsevier},
}

@Article{Aminghafari2007,
  author    = {Aminghafari, Mina and Poggi, Jean-Michel},
  title     = {Forecasting time series using wavelets},
  journal   = {International Journal of Wavelets, Multiresolution and Information Processing},
  year      = {2007},
  volume    = {5},
  number    = {05},
  pages     = {709--724},
  file      = {:references/Forecasting Time Series Using Wavelets/Forecasting Time Series Using Wavelets.pdf:PDF},
  publisher = {World Scientific},
}

@Article{Hyndman2008,
  author    = {Rob J. Hyndman and Yeasmin Khandakar},
  title     = {Automatic Time Series Forecasting: The forecast Package for R},
  journal   = {Journal of Statistical Software},
  year      = {2008},
  volume    = {27},
  number    = {3},
  issn      = {1548-7660},
  abstract  = {Automatic forecasts of large numbers of univariate time series are often needed in business and other contexts. We describe two automatic forecasting algorithms that have been implemented in the forecast package for R. The ﬁrst is based on innovations state space models that underly exponential smoothing methods. The second is a step-wise algorithm for forecasting with ARIMA models. The algorithms are applicable to both seasonal and non-seasonal data, and are compared and illustrated using four real time series. We also brieﬂy describe some of the other functionality available in the forecast package.},
  file      = {:references/Automatic Time Series Forecasting - The Forecast Package for R/Automatic Time Series Forecasting - The Forecast Package for R.pdf:PDF},
  keywords  = {exponential smoothing ; time series ; prediction intervals state space models ; ARIMA models ; automatic forecasting},
  language  = {eng},
  publisher = {Foundation for Open Access Statistics},
}

@Article{Anastassopoulou2020,
  author    = {Anastassopoulou, Cleo and Russo, Lucia and Tsakris, Athanasios and Siettos, Constantinos},
  title     = {Data-based analysis, modelling and forecasting of the COVID-19 outbreak},
  journal   = {PloS one},
  year      = {2020},
  volume    = {15},
  number    = {3},
  pages     = {e0230405},
  file      = {:references/Data-Based Analysis, Modelling and Forecasting of the COVID-19 Outbreak/Data-Based Analysis, Modelling and Forecasting of the COVID-19 Outbreak.pdf:PDF},
  publisher = {Public Library of Science San Francisco, CA USA},
}

@Article{Andrews2000,
  author    = {Andrews, Donald WK and Buchinsky, Moshe},
  title     = {A three-step method for choosing the number of bootstrap repetitions},
  journal   = {Econometrica},
  year      = {2000},
  volume    = {68},
  number    = {1},
  pages     = {23--51},
  file      = {:references/A Three-Step Method for Choosing the Number of Bootstrap Repetitions/A Three-Step Method for Choosing the Number of Bootstrap Repetitions.pdf:PDF},
  publisher = {Wiley Online Library},
}

@Article{Hall1996,
  author    = {Hall, Peter and Horowitz, Joel L},
  title     = {Bootstrap critical values for tests based on generalized-method-of-moments estimators},
  journal   = {Econometrica},
  year      = {1996},
  pages     = {891--916},
  file      = {:references/Bootstrap Critical Values for Tests Based on Generalized-Method-of-Moments Estimators/Bootstrap Critical Values for Tests Based on Generalized-Method-of-Moments Estimators.pdf:PDF},
  publisher = {JSTOR},
}

@Article{Andrews2002,
  author    = {Andrews, Donald WK},
  title     = {Higher-Order Improvements of a Computationally Attractive k-Step Bootstrap for Extremum Estimators},
  journal   = {Econometrica},
  year      = {2002},
  volume    = {70},
  number    = {1},
  pages     = {119--162},
  file      = {:references/Higher-Order Improvements of a Computationally Attractive k-Step Bootstrap for Extremum Estimators/Higher-Order Improvements of a Computationally Attractive k-Step Bootstrap for Extremum Estimators.pdf:PDF},
  publisher = {Wiley Online Library},
}

@Article{Pagan1986,
  author    = {Pagan, Adrian},
  title     = {Two Stage and Related Estimators and Their Applications},
  journal   = {The Review of Economic Studies},
  year      = {1986},
  volume    = {53},
  number    = {4},
  pages     = {517--538},
  file      = {:references/Two Stage and Related Estimators and Their Applications/Two Stage and Related Estimators and Their Applications.pdf:PDF},
  publisher = {Wiley-Blackwell},
}

@InCollection{Newey1994,
  author    = {Whitney K. Newey and Daniel McFadden},
  title     = {Large Sample Estimation and Hypothesis Testing},
  booktitle = {Handbook of Econometrics},
  publisher = {Elsevier},
  year      = {1994},
  volume    = {4},
  chapter   = {36},
  pages     = {2111-2245},
  address   = {Radarweg 29, Amsterdam 1043 NX, Netherlands},
  doi       = {https://doi.org/10.1016/S1573-4412(05)80005-4},
  issn      = {1573-4412},
}

@Book{UniNationsStatisticsDivision2008,
  title     = {UN data: A world of information},
  publisher = {United Nations Statistics Division},
  year      = {2008},
  author    = {{United Nations Statistics Division}},
}

@Article{Aktay2020,
  author  = {Aktay, Ahmet and Bavadekar, Shailesh and Cossoul, Gwen and Davis, John and Desfontaines, Damien and Fabrikant, Alex and Gabrilovich, Evgeniy and Gadepalli, Krishna and Gipson, Bryant and Guevara, Miguel and others},
  title   = {Google COVID-19 community mobility reports: Anonymization process description (version 1.0)},
  journal = {arXiv preprint arXiv:2004.04145},
  year    = {2020},
  file    = {:references/Google COVID19 Community Mobility Reports - Anonymization Process Description/unhighlighted.pdf:PDF},
}

@Article{Kwiatkowski1992,
  author    = {Kwiatkowski, Denis and Phillips, Peter CB and Schmidt, Peter and Shin, Yongcheol},
  title     = {Testing the null hypothesis of stationarity against the alternative of a unit root: How sure are we that economic time series have a unit root?},
  journal   = {Journal of Econometrics},
  year      = {1992},
  volume    = {54},
  number    = {1-3},
  pages     = {159--178},
  file      = {:references/Testing the Null Hypothesis of Stationarity Against the Alternative of a Unit Root/Testing the Null Hypothesis of Stationarity Against the Alternative of a Unit Root.pdf:PDF},
  publisher = {Elsevier},
}

@Article{Liu1989,
  author    = {Liu, Dong C and Nocedal, Jorge},
  title     = {On the limited memory BFGS method for large scale optimization},
  journal   = {Mathematical Programming},
  year      = {1989},
  volume    = {45},
  number    = {1},
  pages     = {503--528},
  file      = {:references/On the Limited Memory BFGS Method for Large Scale Optimization/On the Limited Memory BFGS Method for Large Scale Optimization.pdf:PDF},
  publisher = {Springer},
}

@Article{Martin2021,
  author    = {Martin, Gael M and Loaiza-Maya, Rub{\'e}n and Maneesoonthorn, Worapree and Frazier, David T and Ram{\'\i}rez-Hassan, Andr{\'e}s},
  title     = {Optimal Probabilistic Forecasts: When do They Work?},
  journal   = {International Journal of Forecasting},
  year      = {2022},
  volume    = {38},
  number    = {1},
  pages     = {384--406},
  file      = {:references/Optimal Probabilistic Forecasts - When Do They Work/unhighlighted.pdf:PDF},
  publisher = {Elsevier},
}

@Article{Genre2013,
  author    = {Genre, V{\'e}ronique and Kenny, Geoff and Meyler, Aidan and Timmermann, Allan},
  title     = {Combining Expert Forecasts: Can Anything Beat the Simple Average?},
  journal   = {International Journal of Forecasting},
  year      = {2013},
  volume    = {29},
  number    = {1},
  pages     = {108--121},
  file      = {:references/Combining Expert Forecasts - Can Anything Beat the Simple Average/Combining Expert Forecasts - Can Anything Beat the Simple Average.pdf:PDF},
  publisher = {Elsevier},
}

@Article{Hansen2005,
  author    = {Hansen, Peter Reinhard},
  title     = {A Test for Superior Predictive Ability},
  journal   = {Journal of Business \& Economic Statistics},
  year      = {2005},
  volume    = {23},
  number    = {4},
  pages     = {365--380},
  file      = {:references/A Test for Superior Predictive Ability/A Test for Superior Predictive Ability.pdf:PDF},
  publisher = {Taylor \& Francis},
}

@Article{Gneiting2007a,
  author    = {Gneiting, Tilmann and Balabdaoui, Fadoua and Raftery, Adrian E},
  title     = {Probabilistic forecasts, calibration and sharpness},
  journal   = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  year      = {2007},
  volume    = {69},
  number    = {2},
  pages     = {243--268},
  publisher = {Wiley Online Library},
}

@Article{Bhansali2002,
  author    = {Bhansali, R.J.},
  title     = {Multi-step forecasting},
  journal   = {A Companion to Economic Forecasting. Oxford: Blackwell},
  year      = {2002},
  pages     = {206--221},
  file      = {:references/Multi-Step Forecasting/Multi-Step Forecasting.pdf:PDF},
  publisher = {Wiley Online Library},
}

@Article{Taieb2012,
  author    = {Taieb, Souhaib Ben and Bontempi, Gianluca and Atiya, Amir F and Sorjamaa, Antti},
  title     = {A review and comparison of strategies for multi-step ahead time series forecasting based on the NN5 forecasting competition},
  journal   = {Expert systems with applications},
  year      = {2012},
  volume    = {39},
  number    = {8},
  pages     = {7067--7083},
  file      = {:references/A Review and Comparison of Strategies for Multi-Step Ahead Time Series Forecasting Based on the NN5 Forecasting Competition/A Review and Comparison of Strategies for Multi-Step Ahead Time Series Fo.pdf:PDF},
  publisher = {Elsevier},
}

@Article{Makridakis2020a,
  author = {Makridakis, Spyros and Spiliotis, Evangelos and Assimakopoulos, Vassilis},
  title  = {The M5 Accuracy competition: Results, findings and conclusions},
  year   = {2020},
  month  = oct,
}

@Article{Makridakis2020b,
  author = {Makridakis, Spyros and Spiliotis, Evangelos and Assimakopoulos, Vassilis and Chen, Zhi and Gaba, Anil and Tsetlin, Ilia and Winkler, Robert},
  title  = {The M5 Uncertainty competition: Results, findings and conclusions},
  year   = {2020},
  month  = nov,
}

@Article{Smyl2020,
  author    = {Smyl, Slawek},
  title     = {A hybrid method of exponential smoothing and recurrent neural networks for time series forecasting},
  journal   = {International Journal of Forecasting},
  year      = {2020},
  volume    = {36},
  number    = {1},
  pages     = {75--85},
  file      = {:references/A Hybrid Method of Exponential Smoothing and Recurrent Neural Networks for Time Series Forecasting/A Hybrid Method of Exponential Smoothing and Recurrent Neural Networks for Time Series Forecasting.pdf:PDF},
  publisher = {Elsevier},
}

@Article{Phillips1979,
  author    = {Phillips, Peter CB},
  title     = {The sampling distribution of forecasts from a first-order autoregression},
  journal   = {Journal of Econometrics},
  year      = {1979},
  volume    = {9},
  number    = {3},
  pages     = {241--261},
  file      = {:references/The Sampling Distribution of Forecasts from a First-Order Autoregression/The Sampling Distribution of Forecasts from a First-Order Autoregression.pdf:PDF},
  publisher = {Elsevier},
}

@Article{Freeland2004,
  author    = {Freeland, R Keith and McCabe, Brendan PM},
  title     = {Forecasting discrete valued low count time series},
  journal   = {International Journal of Forecasting},
  year      = {2004},
  volume    = {20},
  number    = {3},
  pages     = {427--434},
  file      = {:references/Forecasting Discrete Valued Low Count Time Series/unhighlighted.pdf:PDF},
  publisher = {Elsevier},
}

@Article{DeGooijer2006,
  author    = {De Gooijer, Jan G and Hyndman, Rob J},
  title     = {25 years of time series forecasting},
  journal   = {International Journal of Forecasting},
  year      = {2006},
  volume    = {22},
  number    = {3},
  pages     = {443--473},
  file      = {:references/25 Years of Time Series Forecasting/25 Years of Time Sesries Forecasting.pdf:PDF},
  publisher = {Elsevier},
}

@Article{Rodriguez2009,
  author    = {Rodriguez, Alejandro and Ruiz, Esther},
  title     = {Bootstrap prediction intervals in state--space models},
  journal   = {Journal of Time Series Analysis},
  year      = {2009},
  volume    = {30},
  number    = {2},
  pages     = {167--178},
  file      = {:references/Bootstrap Prediction Intervals in State-Space Models/unhighlighted.pdf:PDF},
  publisher = {Wiley Online Library},
}

@Article{Rodriguez2012,
  author    = {Rodriguez, Alejandro and Ruiz, Esther},
  title     = {Bootstrap prediction mean squared errors of unobserved states based on the Kalman filter with estimated parameters},
  journal   = {Computational Statistics \& Data Analysis},
  year      = {2012},
  volume    = {56},
  number    = {1},
  pages     = {62--74},
  file      = {:references/Bootstrap Prediction Mean Squared Errors of Unobserved States Based on the Kalman Filter with Estimated Parameters/unhighlighted.pdf:PDF},
  publisher = {Elsevier},
}

@Book{Schweder2016,
  title     = {Confidence, likelihood, probability},
  publisher = {Cambridge University Press},
  year      = {2016},
  author    = {Schweder, Tore and Hjort, Nils Lid},
  volume    = {41},
}

@Article{Wolf2015,
  author    = {Wolf, Michael and Wunderli, Dan},
  title     = {Bootstrap joint prediction regions},
  journal   = {Journal of Time Series Analysis},
  year      = {2015},
  volume    = {36},
  number    = {3},
  pages     = {352--376},
  file      = {:references/Bootstrap Joint Prediction Regions/unhighlighted.pdf:PDF},
  publisher = {Wiley Online Library},
}

@Article{Baran2018,
  author    = {Baran, S{\'a}ndor and Lerch, Sebastian},
  title     = {Combining Predictive Distributions for the Statistical Post-Processing of Ensemble Forecasts},
  journal   = {International Journal of Forecasting},
  year      = {2018},
  volume    = {34},
  number    = {3},
  pages     = {477--496},
  file      = {:references/Combining Predictive Distributions for the Statistical Post-Processing of Ensemble Forecasts/unhighlighted.pdf:PDF},
  publisher = {Elsevier},
}

@Article{Post2019,
  author    = {Post, Thierry and Karabat{\i}, Sel{\c{c}}uk and Arvanitis, Stelios},
  title     = {Robust optimization of forecast combinations},
  journal   = {International Journal of Forecasting},
  year      = {2019},
  volume    = {35},
  number    = {3},
  pages     = {910--926},
  file      = {:references/Robust Optimization of Forecast Combinations/unhighlighted.pdf:PDF},
  publisher = {Elsevier},
}

@Article{Wang2018,
  author    = {Wang, Lin and Wang, Zhigang and Qu, Hui and Liu, Shan},
  title     = {Optimal Forecast Combination Based on Neural Networks for Time Series Forecasting},
  journal   = {Applied Soft Computing},
  year      = {2018},
  volume    = {66},
  pages     = {1--17},
  file      = {:references/Optimal Forecast Combination Based on Neural Networks for Time Series Forecasting/unhighlighted.pdf:PDF},
  publisher = {Elsevier},
}

@Article{Thorey2018,
  author    = {Thorey, Jean and Chaussin, Christophe and Mallet, Vivien},
  title     = {Ensemble Forecast of Photovoltaic Power with Online CRPS Learning},
  journal   = {International Journal of Forecasting},
  year      = {2018},
  volume    = {34},
  number    = {4},
  pages     = {762--773},
  file      = {:references/Ensemble Forecast of Photovoltaic Power with Online CRPS Learning/unhighlighted.pdf:PDF},
  publisher = {Elsevier},
}

@Article{Yan2021,
  author    = {Yan, Xiaodong and Wang, Hongni and Wang, Wei and Xie, Jinhan and Ren, Yanyan and Wang, Xinjun},
  title     = {Optimal model averaging forecasting in high-dimensional survival analysis},
  journal   = {International Journal of Forecasting},
  year      = {2021},
  file      = {:references/Optimal Model Averaging Forecasting in High-Dimensional Survival Analysis/unhighlighted.pdf:PDF},
  publisher = {Elsevier},
}

@Article{Taylor2020,
  author    = {Taylor, James W},
  title     = {Forecast Combinations for Value at Risk and Expected Shortfall},
  journal   = {International Journal of Forecasting},
  year      = {2020},
  volume    = {36},
  number    = {2},
  pages     = {428--441},
  file      = {:references/Forecast Combinations for Value At Risk and Expected Shortfall/Forecast Combinations for Value at Risk and Expected Shortfall.pdf:PDF},
  publisher = {Elsevier},
}

@Article{Frazier2017,
  author    = {Frazier, David T and Renault, Eric},
  title     = {Efficient Two-Step Estimation via Targeting},
  journal   = {Journal of Econometrics},
  year      = {2017},
  volume    = {201},
  number    = {2},
  pages     = {212--227},
  publisher = {Elsevier},
}

@Article{Qian2021,
  author    = {Qian, Wei and Rolling, Craig A and Cheng, Gang and Yang, Yuhong},
  title     = {Combining forecasts for universally optimal performance},
  journal   = {International Journal of Forecasting},
  year      = {2021},
  publisher = {Elsevier},
}

@Article{Clements2011,
  author    = {Clements, Michael P and Harvey, David I},
  title     = {Combining probability forecasts},
  journal   = {International Journal of Forecasting},
  year      = {2011},
  volume    = {27},
  number    = {2},
  pages     = {208--223},
  file      = {:references/Combining Probability Forecasts 2/unhighlighted.pdf:PDF},
  publisher = {Elsevier},
}

@TechReport{Ganics2018,
  author      = {Gergely Akos Ganics},
  title       = {{Optimal density forecast combinations}},
  institution = {Banco de España},
  year        = {2018},
  type        = {Working Papers},
  number      = {1751},
  month       = Jan,
  abstract    = {How should researchers combine predictive densities to improve their forecasts? I propose consistent estimators of weights which deliver density forecast combinations approximating the true predictive density, conditional on the researcher’s information set. Monte Carlo simulations confi rm that the proposed methods work well for sample sizes of practical interest. In an empirical example of forecasting monthly US industrial production, I demonstrate that the estimator delivers density forecasts which are superior to well-known benchmarks, such as the equal weights scheme. Specifi cally, I show that housing permits had valuable predictive power before and after the Great Recession. Furthermore, stock returns and corporate bond spreads proved to be useful predictors during the recent crisis, suggesting that fi nancial variables help with density forecasting in a highly leveraged economy.},
  file        = {:references/Optimal Density Forecast Combinations/unhighlighted.pdf:PDF},
  keywords    = {density forecasts; forecast combinations; probability integral transform; Kolmogorov-Smirnov; Cramer},
}

@Article{Kapetanios2015,
  author    = {Kapetanios, G and Mitchell, James and Price, Simon and Fawcett, Nicholas},
  title     = {Generalised density forecast combinations},
  journal   = {Journal of Econometrics},
  year      = {2015},
  volume    = {188},
  number    = {1},
  pages     = {150--165},
  file      = {:references/Generalised Density Forecast Combinations/unhighlighted.pdf:PDF},
  publisher = {Elsevier},
}

@Article{Knueppel2021,
  author   = {Knüppel, Malte and Krüger, Fabian},
  title    = {Forecast Uncertainty, Disagreement, and the Linear Pool},
  journal  = {Journal of Applied Econometrics},
  year     = {2021},
  abstract = {Summary The linear pool is the most popular method for combining density forecasts. We analyze its implications concerning forecast uncertainty, using a new framework that focuses on the means and variances of the individual and combined forecasts. Our results show that, if the variance predictions of the individual forecasts are unbiased, the well-known `disagreement' component of the linear pool exacerbates the upward bias of its variance prediction. This finding suggests the removal of the disagreement component from the linear pool. The resulting centered linear pool outperforms the linear pool in simulations and an empirical application to inflation.},
  file     = {:references/Forecast Uncertainty, Disagreement, and the Linear Pool/unhighlighted.pdf:PDF},
}

@InCollection{Aastveit2019,
  author    = {Knut Are Aastveit and James Mitchell and Francesco Ravazzolo and van Dijk, Herman K},
  title     = {The Evolution of Forecast Density Combinations in Economics},
  booktitle = {Oxford Research Encyclopedia of Economics and Finance},
  publisher = {Oxford University Press},
  year      = {2019},
  address   = {Great Clarendon Street, Oxford, OX2 6DP, United Kingdom},
  file      = {:references/The Evolution of Forecast Density Combinations in Economics/highlighted.pdf:PDF},
}

@Book{Bernardo2009,
  title     = {Bayesian theory},
  publisher = {John Wiley \& Sons},
  year      = {2009},
  author    = {Bernardo, Jos{\'e} M and Smith, Adrian FM},
  volume    = {405},
}

@Article{Kascha2010,
  author    = {Kascha, Christian and Ravazzolo, Francesco},
  title     = {Combining inflation density forecasts},
  journal   = {Journal of Forecasting},
  year      = {2010},
  volume    = {29},
  number    = {1-2},
  pages     = {231--250},
  file      = {:references/Combining Inflation Density Forecasts/unhighlighted.pdf:PDF},
  publisher = {Wiley Online Library},
}

@Article{Aastveit2018,
  author    = {Aastveit, Knut Are and Ravazzolo, Francesco and van Dijk, Herman K},
  title     = {Combined Density Nowcasting in an Uncertain Economic Environment},
  journal   = {Journal of Business \& Economic Statistics},
  year      = {2018},
  volume    = {36},
  number    = {1},
  pages     = {131--145},
  file      = {:references/Combined Density Nowcasting in an Uncertain Economic Environment/unhighlighted.pdf:PDF},
  publisher = {Taylor \& Francis},
}

@Article{Billio2013,
  author    = {Billio, Monica and Casarin, Roberto and Ravazzolo, Francesco and van Dijk, Herman K},
  title     = {Time-Varying Combinations of Predictive Densities Using Nonlinear Filtering},
  journal   = {Journal of Econometrics},
  year      = {2013},
  volume    = {177},
  number    = {2},
  pages     = {213--232},
  file      = {:references/Time-Varying Combinations of Predictive Densities using Nonlinear Filtering/unhighlighted.pdf:PDF},
  publisher = {Elsevier},
}

@Article{Casarin2015,
  author    = {Casarin, Roberto and Leisen, Fabrizio and Molina, German and ter Horst, Enrique},
  title     = {A Bayesian Beta Markov Random Field Calibration of the Term Structure of Implied Risk Neutral Densities},
  journal   = {Bayesian Analysis},
  year      = {2015},
  volume    = {10},
  number    = {4},
  pages     = {791--819},
  file      = {:references/A Bayesian Beta Markov Random Field Calibration of the Term Structure of Implied Risk Neutral Densities/unhighlighted.pdf:PDF},
  publisher = {International Society for Bayesian Analysis},
}

@Article{Casarin2016,
  author    = {Casarin, Roberto and Mantoan, Giulia and Ravazzolo, Francesco},
  title     = {Bayesian Calibration of Generalized Pools of Predictive Distributions},
  journal   = {Econometrics},
  year      = {2016},
  volume    = {4},
  number    = {1},
  pages     = {17},
  file      = {:references/A Bayesian Beta Markov Random Field Calibration of the Term Structure of Implied Risk Neutral Densities/unhighlighted.pdf:PDF},
  publisher = {Multidisciplinary Digital Publishing Institute},
}

@Article{Pettenuzzo2016,
  author    = {Pettenuzzo, Davide and Ravazzolo, Francesco},
  title     = {Optimal Portfolio Choice Under Decision-Based Model Combinations},
  journal   = {Journal of Applied Econometrics},
  year      = {2016},
  volume    = {31},
  number    = {7},
  pages     = {1312--1332},
  file      = {:references/Optimal Portfolio Choice Under Decision-Based Model Combinations/unhighlighted.pdf:PDF},
  publisher = {Wiley Online Library},
}

@Article{McAlinn2019,
  author    = {McAlinn, Kenichiro and West, Mike},
  title     = {Dynamic Bayesian Predictive Synthesis in Time Series Forecasting},
  journal   = {Journal of Econometrics},
  year      = {2019},
  volume    = {210},
  number    = {1},
  pages     = {155--169},
  file      = {:references/Dynamic Bayesian Predictive Synthesis in Time Series Forecasting/unhighlighted.pdf:PDF},
  publisher = {Elsevier},
}

@Article{Bassetti2018,
  author    = {Bassetti, Federico and Casarin, Roberto and Ravazzolo, Francesco},
  title     = {Bayesian Nonparametric Calibration and Combination of Predictive Distributions},
  journal   = {Journal of the American Statistical Association},
  year      = {2018},
  volume    = {113},
  number    = {522},
  pages     = {675--685},
  file      = {:references/Bayesian Nonparametric Calibration and Combination of Predictive Distributions/unhighlighted.pdf:PDF},
  publisher = {Taylor \& Francis},
}

@Article{Bastuerk2019,
  author    = {Ba{\c{s}}t{\"u}rk, Nalan and Borowska, Agnieszka and Grassi, Stefano and Hoogerheide, Lennart and van Dijk, Herman K},
  title     = {Forecast Density Combinations of Dynamic Models and Data Driven Portfolio Strategies},
  journal   = {Journal of Econometrics},
  year      = {2019},
  volume    = {210},
  number    = {1},
  pages     = {170--186},
  file      = {:references/Forecast Density Combinations of Dynamic Models and Data Driven Portfolio Strategies/unhighlighted.pdf:PDF},
  publisher = {Elsevier},
}

@Article{Fatemi2018,
  author    = {Fatemi, Seyyed A and Kuh, Anthony and Fripp, Matthias},
  title     = {Parametric methods for probabilistic forecasting of solar irradiance},
  journal   = {Renewable Energy},
  year      = {2018},
  volume    = {129},
  pages     = {666--676},
  file      = {:references/Parametric Methods for Probabilistic Forecasting of Solar Irradiance/unhighlighted.pdf:PDF},
  publisher = {Elsevier},
}

@Article{Beekman2020,
  author    = {Beekman, Jared A and Woodaman, Ronald FA and Buede, Dennis M},
  title     = {A Review of Probabilistic Opinion Pooling Algorithms with Application to Insider Threat Detection},
  journal   = {Decision Analysis},
  year      = {2020},
  volume    = {17},
  number    = {1},
  pages     = {39--55},
  file      = {:references/A Review of Probabilistic Opinion Pooling Algorithms with Application to Insider Threat Detection/unhighlighted.pdf:PDF},
  publisher = {INFORMS},
}

@Article{Lahiri2015,
  author    = {Lahiri, Kajal and Peng, Huaming and Zhao, Yongchen},
  title     = {Testing the value of probability forecasts for calibrated combining},
  journal   = {International Journal of Forecasting},
  year      = {2015},
  volume    = {31},
  number    = {1},
  pages     = {113--129},
  file      = {:references/Testing the Value of Probability Forecasts for Calibtrated Combining/unhighlighted.pdf:PDF},
  publisher = {Elsevier},
}

@Article{Bogner2017,
  author    = {Bogner, Konrad and Liechti, Katharina and Zappa, Massimiliano},
  title     = {Combining quantile forecasts and predictive distributions of streamflows},
  journal   = {Hydrology and Earth System Sciences},
  year      = {2017},
  volume    = {21},
  number    = {11},
  pages     = {5493--5502},
  file      = {:references/Combining Quantile Forecasts and Predictive Distributions of Streamflows/unhighlighted.pdf:PDF},
  publisher = {Copernicus GmbH},
}

@Article{Satopaeae2014,
  author    = {Satop{\"a}{\"a}, Ville A and Baron, Jonathan and Foster, Dean P and Mellers, Barbara A and Tetlock, Philip E and Ungar, Lyle H},
  title     = {Combining Multiple Probability Predictions Using a Simple Logit Model},
  journal   = {International Journal of Forecasting},
  year      = {2014},
  volume    = {30},
  number    = {2},
  pages     = {344--356},
  file      = {:references/Combining Multiple Probability Predictions Using a Simple Logit Model/unhighlighted.pdf:PDF},
  publisher = {Elsevier},
}

@Article{Allard2012,
  author    = {Allard, Denis and Comunian, Alessandro and Renard, Philippe},
  title     = {Probability aggregation methods in geoscience},
  journal   = {Mathematical Geosciences},
  year      = {2012},
  volume    = {44},
  number    = {5},
  pages     = {545--581},
  file      = {:references/Probability Aggregation Methods in Geoscience/unhighlighted.pdf:PDF},
  publisher = {Springer},
}

@Article{Besancon2021,
  author   = {Mathieu Besançon and Theodore Papamarkou and David Anthoff and Alex Arslan and Simon Byrne and Dahua Lin and John Pearson},
  title    = {Distributions.jl: Definition and Modeling of Probability Distributions in the JuliaStats Ecosystem},
  journal  = {Journal of Statistical Software, Articles},
  year     = {2021},
  volume   = {98},
  number   = {16},
  pages    = {1--30},
  issn     = {1548-7660},
  abstract = {Random variables and their distributions are a central part in many areas of statistical methods. The Distributions.jl package provides Julia users and developers tools for working with probability distributions, leveraging Julia features for their intuitive and flexible manipulation, while remaining highly efficient through zero-cost abstractions.},
  doi      = {10.18637/jss.v098.i16},
  file     = {:references/Distributions dot jl - Definition and Modeling of Probability Distributions in the JuliaStats Ecosystem/unhighlighted.pdf:PDF},
  keywords = {Julia; distributions; modeling; interface; mixture; KDE; sampling; probabilistic programming; inference},
}

@Article{Meent2018,
  author  = {van de Meent, Jan-Willem and Paige, Brooks and Yang, Hongseok and Wood, Frank},
  title   = {An introduction to probabilistic programming},
  journal = {arXiv preprint arXiv:1809.10756},
  year    = {2018},
  file    = {:references/An Introduction to Probabilistic Programming/unhighlighted.pdf:PDF},
}

@Article{Fissler2016,
  author    = {Fissler, Tobias and Ziegel, Johanna F},
  title     = {Higher order elicitability and Osband’s principle},
  journal   = {The Annals of Statistics},
  year      = {2016},
  volume    = {44},
  number    = {4},
  pages     = {1680--1707},
  file      = {:references/Higher Order Elicitability and Osband's Principle/unhighlighted.pdf:PDF},
  publisher = {Institute of Mathematical Statistics},
}

@Article{Gruenwald2004,
  author    = {Gr{\"u}nwald, Peter D and Dawid, A Philip},
  title     = {Game theory, maximum entropy, minimum discrepancy and robust Bayesian decision theory},
  journal   = {the Annals of Statistics},
  year      = {2004},
  volume    = {32},
  number    = {4},
  pages     = {1367--1433},
  file      = {:references/Game Theory, Maximum Entropy, Minimum Discrepancy and Robust Bayesian Decision Theory/unhighlighted.pdf:PDF},
  publisher = {Institute of Mathematical Statistics},
}

@Article{Patton2020,
  author    = {Patton, Andrew J},
  title     = {Comparing possibly misspecified forecasts},
  journal   = {Journal of Business \& Economic Statistics},
  year      = {2020},
  volume    = {38},
  number    = {4},
  pages     = {796--809},
  file      = {:references/Comparing Possibly Misspecified Forecasts/unhighlighted.pdf:PDF},
  publisher = {Taylor \& Francis},
}

@Article{Wallis2005,
  author    = {Wallis, Kenneth F},
  title     = {Combining density and interval forecasts: a modest proposal},
  journal   = {Oxford Bulletin of Economics and Statistics},
  year      = {2005},
  volume    = {67},
  pages     = {983--994},
  file      = {:references/Combining Density and Interval Forecasts - A Modest Proposal/unhighlighted.pdf:PDF},
  publisher = {Wiley Online Library},
}

@Article{White2000,
  author    = {White, Halbert},
  title     = {A reality check for data snooping},
  journal   = {Econometrica},
  year      = {2000},
  volume    = {68},
  number    = {5},
  pages     = {1097--1126},
  file      = {:references/A Reality Check for Data Snooping/unhighlighted.pdf:PDF},
  publisher = {Wiley Online Library},
}

@InBook{Hayashi2000a,
  chapter   = {7},
  pages     = {445 -- 506},
  title     = {Extremum Estimators},
  publisher = {Princeton University Press},
  year      = {2000},
  author    = {Hayashi, F.},
  booktitle = {Econometrics},
}

@Misc{Casarin2019,
  author       = {Casarin, Roberto and Grassi, Stefano and Ravazzollo, Francesco and van Dijk, Herman K},
  title        = {Forecast Density Combinations With Dynamic Learning for Large Data Sets in Economics and Finance},
  howpublished = {Tinbergen Institute Discussion Paper 2019-025/III},
  year         = {2019},
}

@Article{Pesaran2002,
  author    = {Pesaran, M Hashem and Skouras, Spyros},
  title     = {Decision-based methods for forecast evaluation},
  journal   = {A Companion to Economic Forecasting},
  year      = {2002},
  pages     = {241--267},
  file      = {:references/Decision-Based Methods for Forecast Evaluation/unhighlighted.pdf:PDF},
  publisher = {Blackwell: Oxford},
}

@Article{Granger2006,
  author    = {Granger, Clive WJ and Machina, Mark J},
  title     = {Forecasting and decision theory},
  journal   = {Handbook of Economic Forecasting},
  year      = {2006},
  volume    = {1},
  pages     = {81--98},
  publisher = {Elsevier},
}

@Article{Chen2007,
  author    = {Chen, Xiaohong},
  title     = {Large sample sieve estimation of semi-nonparametric models},
  journal   = {Handbook of Econometrics},
  year      = {2007},
  volume    = {6},
  pages     = {5549--5632},
  file      = {:references/Large Sample Sieve Estimation of Semi-Nonparametric Models/Large Sample Sieve Estimation of Semi-Nonparametric Models.pdf:PDF},
  publisher = {Elsevier},
}

@Article{Genovese2000,
  author    = {Genovese, Christopher R and Wasserman, Larry},
  title     = {Rates of convergence for the Gaussian mixture sieve},
  journal   = {The Annals of Statistics},
  year      = {2000},
  volume    = {28},
  number    = {4},
  pages     = {1105--1127},
  file      = {:references/Rates of Convergence for the Gaussian Mixture Sieve/Rates of Convergence for the Gaussian Mixture Sieve.pdf:PDF},
  publisher = {Institute of Mathematical Statistics},
}

@Book{Billingsley1995,
  title     = {Probability and Measure},
  publisher = {John Wiley \& Sons},
  year      = {1995},
  author    = {Billingsley, Patrick},
}

@Article{Panaretos2019,
  author    = {Panaretos, Victor M and Zemel, Yoav},
  title     = {Statistical aspects of Wasserstein distances},
  journal   = {Annual Review of Statistics and its Application},
  year      = {2019},
  volume    = {6},
  pages     = {405--431},
  file      = {:references/Statistical Aspects of Wasserstein Distances/Statistical Aspects of Wasserstein Distances.pdf:PDF},
  publisher = {Annual Reviews},
}

@Article{Gibbs2002,
  author    = {Gibbs, Alison L and Su, Francis Edward},
  title     = {On choosing and bounding probability metrics},
  journal   = {International statistical review},
  year      = {2002},
  volume    = {70},
  number    = {3},
  pages     = {419--435},
  file      = {:references/On Choosing and Bounding Probability Metrics/On Choosing and Bounding Probability Metrics.pdf:PDF},
  publisher = {Wiley Online Library},
}

@Article{Schwarz1978,
  author    = {Schwarz, Gideon},
  title     = {Estimating the dimension of a model},
  journal   = {The Annals of Statistics},
  year      = {1978},
  pages     = {461--464},
  publisher = {JSTOR},
}

@Article{Hyndman2006,
  author    = {Hyndman, Rob J and Koehler, Anne B},
  title     = {Another look at measures of forecast accuracy},
  journal   = {International Journal of Forecasting},
  year      = {2006},
  volume    = {22},
  number    = {4},
  pages     = {679--688},
  file      = {:references/Another Look at Measures of Forecast Accuracy/unhighlighted.pdf:PDF},
  publisher = {Elsevier},
}

@InCollection{PesaranM.Hashem2004DMfF,
  author    = {Pesaran, M. Hashem and Skouras, Spyros},
  title     = {Decision‐Based Methods for Forecast Evaluation},
  booktitle = {A Companion to Economic Forecasting},
  publisher = {Blackwell Publishing Ltd},
  year      = {2004},
  pages     = {241--267},
  address   = {Malden, MA, USA},
  isbn      = {0631215697},
  copyright = {Copyright © 2002, 2004 by Blackwell Publishing Ltd},
  keywords  = {decision‐based forecast evaluation ; decision‐based methods ; forecast evaluation ; investors ; quadratic cost functions},
  language  = {eng},
}

@Article{Andrews1999,
  author    = {Andrews, Donald W. K},
  title     = {Estimation When a Parameter is on a Boundary},
  journal   = {Econometrica},
  year      = {1999},
  volume    = {67},
  number    = {6},
  pages     = {1341--1383},
  issn      = {0012-9682},
  abstract  = {This paper establishes the asymptotic distribution of an extremum estimator when the true parameter lies on the boundary of the parameter space. The boundary may be linear, curved, and/or kinked. Typically the asymptotic distribution is a function of a multivariate normal distribution in models without stochastic trends and a function of a multivariate Brownian motion in models with stochastic trends. The results apply to a wide variety of estimators and models. Examples treated in the paper are: (i) quasi-ML estimation of a random coefficients regression model with some coefficient variances equal to zero and (ii) LS estimation of an augmented Dickey-Fuller regression with unit root and time trend parameters on the boundary of the parameter space.},
  address   = {Oxford, UK and Boston, USA},
  copyright = {Copyright 1999 Econometric Society},
  file      = {:references/Estimation When a Parameter is on a Boundary/unhighlighted.pdf:PDF},
  keywords  = {Applications ; Asymptotic distribution ; Bleeding time ; Business & Economics ; Consistent estimators ; Distribution theory ; Economics ; Estimation methods ; Estimators ; Exact sciences and technology ; Extrema ; Inequality restrictions ; Inference from stochastic processes; time series analysis ; Insurance, economics, finance ; Linear inference, regression ; Mathematical independent variables ; Mathematical Methods In Social Sciences ; Mathematics ; Mathematics, Interdisciplinary Applications ; Objective functions ; Partial derivatives ; Physical Sciences ; Probability and statistics ; Random coefficients regression ; Regression coefficients ; Science & Technology ; Sciences and techniques of general use ; Social Sciences ; Social Sciences, Mathematical Methods ; Statistics ; Statistics & Probability ; Stochastic trends ; Sufficient conditions ; Unit root model},
  language  = {eng},
  publisher = {Blackwell Publishers Ltd},
}

@Article{Brownlees2006,
  author    = {Brownlees, Christian T and Gallo, Giampiero M},
  title     = {Financial econometric analysis at ultra-high frequency: Data handling concerns},
  journal   = {Computational Statistics \& Data Analysis},
  year      = {2006},
  volume    = {51},
  number    = {4},
  pages     = {2232--2245},
  file      = {:references/Financial Econometric Analysis at Ultra-High Frequency - Data Handling Concerns/unhighlighted.pdf:PDF},
  publisher = {Elsevier},
}

@Article{Maneesoonthorn2012,
  author    = {Maneesoonthorn, Worapree and Martin, Gael M and Forbes, Catherine S and Grose, Simone D},
  title     = {Probabilistic forecasts of volatility and its risk premia},
  journal   = {Journal of Econometrics},
  year      = {2012},
  volume    = {171},
  number    = {2},
  pages     = {217--236},
  file      = {:references/Probability Forecasts of Volatility and its Risk Premia/unhighlighted.pdf:PDF},
  publisher = {Elsevier},
}

@Misc{Wang2022,
  author       = {Wang, Xiaoqian and Hyndman, Rob J and Li, Feng and Kang, Yanfei},
  title        = {Forecast Combinations: an Over 50-Year Review},
  howpublished = {arXiv:2205.04216},
  year         = {2022},
  copyright    = {arXiv.org perpetual, non-exclusive license},
  doi          = {10.48550/ARXIV.2205.04216},
  keywords     = {Methodology (stat.ME), Applications (stat.AP), Computation (stat.CO), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher    = {arXiv},
}

@Comment{jabref-meta: databaseType:bibtex;}
